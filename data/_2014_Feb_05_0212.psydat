ccopy_reg
_reconstructor
p1
(cpsychopy.data
ExperimentHandler
p2
c__builtin__
object
p3
NtRp4
(dp5
S'originPath'
p6
NsS'dataFileName'
p7
Vdata/_2014_Feb_05_0212
p8
sS'runtimeInfo'
p9
NsS'name'
p10
S'igt'
p11
sS'dataNames'
p12
(lp13
S'com_choice'
p14
aS'sub_choice'
p15
aS'feedback'
p16
aS'key_pressed.keys'
p17
aS'key_pressed.rt'
p18
asS'extraInfo'
p19
(dp20
S'date'
p21
V2014_Feb_05_0212
p22
sS'frameRate'
p23
cnumpy.core.multiarray
scalar
p24
(cnumpy
dtype
p25
(S'f8'
I0
I1
tRp26
(I3
S'<'
NNNI-1
I-1
I0
tbS'`\x83\x14\xda\x93\xe5M@'
tRp27
sS'expName'
p28
g11
sVsession
p29
V001
p30
sVparticipant
p31
V
ssS'loopsUnfinished'
p32
(lp33
sS'saveWideText'
p34
I00
sS'thisEntry'
p35
(dp36
sS'version'
p37
S''
sS'_paramNamesSoFar'
p38
(lp39
VsessionN
p40
aVcom_result_pool_s2
p41
aVcom_condi
p42
aVcom_result_pool
p43
asS'entries'
p44
(lp45
(dp46
g43
I2
sg15
S'Black card'
p47
sg42
I0
sg23
g27
sS'Sessions.thisN'
p48
I0
sS'external_loop.thisN'
p49
I0
sg29
g30
sg18
F0.39904189109802246
sg21
g22
sg16
S'Loss'
p50
sS'Sessions.thisIndex'
p51
g24
(g25
(S'i4'
I0
I1
tRp52
(I3
S'<'
NNNI-1
I-1
I0
tbS'\x00\x00\x00\x00'
tRp53
sg31
V
sS'external_loop.thisTrialN'
p54
I0
sg14
S'Red card'
p55
sg41
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p56
I0
sS'Sessions.thisRepN'
p57
I0
sg40
Vs1
p58
sS'external_loop.thisRepN'
p59
I0
sS'external_loop.thisIndex'
p60
g24
(g52
S'\x00\x00\x00\x00'
tRp61
sa(dp62
g29
g30
sg43
I1
sS'Sessions.thisIndex'
p63
g24
(g52
S'\x01\x00\x00\x00'
tRp64
sg31
V
sg15
S'N/A'
p65
sS'external_loop.thisTrialN'
p66
I0
sg23
g27
sg42
I1
sg16
g65
sg14
g47
sS'Sessions.thisN'
p67
I1
sg41
I2
sS'external_loop.thisN'
p68
I0
sg28
g11
sg17
NsS'Sessions.thisTrialN'
p69
I1
sS'Sessions.thisRepN'
p70
I0
sg21
g22
sg40
g58
sS'external_loop.thisIndex'
p71
g61
sS'external_loop.thisRepN'
p72
I0
sa(dp73
g43
I1
sg15
g47
sg42
I2
sg23
g27
sS'Sessions.thisN'
p74
I2
sS'external_loop.thisN'
p75
I0
sg29
g30
sg18
F0.60162901878356934
sg21
g22
sg16
S'Win'
p76
sS'Sessions.thisIndex'
p77
g24
(g52
S'\x02\x00\x00\x00'
tRp78
sg31
V
sS'external_loop.thisTrialN'
p79
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p80
I2
sS'Sessions.thisRepN'
p81
I0
sg40
g58
sS'external_loop.thisRepN'
p82
I0
sS'external_loop.thisIndex'
p83
g61
sa(dp84
g43
I2
sg15
g55
sg42
I3
sg23
g27
sS'Sessions.thisN'
p85
I3
sS'external_loop.thisN'
p86
I0
sg29
g30
sg18
F0.44570803642272949
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p87
g24
(g52
S'\x03\x00\x00\x00'
tRp88
sg31
V
sS'external_loop.thisTrialN'
p89
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p90
I3
sS'Sessions.thisRepN'
p91
I0
sg40
g58
sS'external_loop.thisRepN'
p92
I0
sS'external_loop.thisIndex'
p93
g61
sa(dp94
g43
I1
sg15
g55
sg42
I4
sg23
g27
sS'Sessions.thisN'
p95
I4
sS'external_loop.thisN'
p96
I0
sg29
g30
sg18
F0.43543791770935059
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p97
g24
(g52
S'\x04\x00\x00\x00'
tRp98
sg31
V
sS'external_loop.thisTrialN'
p99
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p100
I4
sS'Sessions.thisRepN'
p101
I0
sg40
g58
sS'external_loop.thisRepN'
p102
I0
sS'external_loop.thisIndex'
p103
g61
sa(dp104
g43
I2
sg15
g55
sg42
I5
sg23
g27
sS'Sessions.thisN'
p105
I5
sS'external_loop.thisN'
p106
I0
sg29
g30
sg18
F0.4490962028503418
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p107
g24
(g52
S'\x05\x00\x00\x00'
tRp108
sg31
V
sS'external_loop.thisTrialN'
p109
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p110
I5
sS'Sessions.thisRepN'
p111
I0
sg40
g58
sS'external_loop.thisRepN'
p112
I0
sS'external_loop.thisIndex'
p113
g61
sa(dp114
g43
I1
sg15
g55
sg42
I6
sg23
g27
sS'Sessions.thisN'
p115
I6
sS'external_loop.thisN'
p116
I0
sg29
g30
sg18
F0.59116196632385254
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p117
g24
(g52
S'\x06\x00\x00\x00'
tRp118
sg31
V
sS'external_loop.thisTrialN'
p119
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p120
I6
sS'Sessions.thisRepN'
p121
I0
sg40
g58
sS'external_loop.thisRepN'
p122
I0
sS'external_loop.thisIndex'
p123
g61
sa(dp124
g43
I2
sg15
g47
sg42
I7
sg23
g27
sS'Sessions.thisN'
p125
I7
sS'external_loop.thisN'
p126
I0
sg29
g30
sg18
F0.45003509521484375
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p127
g24
(g52
S'\x07\x00\x00\x00'
tRp128
sg31
V
sS'external_loop.thisTrialN'
p129
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p130
I7
sS'Sessions.thisRepN'
p131
I0
sg40
g58
sS'external_loop.thisRepN'
p132
I0
sS'external_loop.thisIndex'
p133
g61
sa(dp134
g43
I2
sg15
g55
sg42
I8
sg23
g27
sS'Sessions.thisN'
p135
I8
sS'external_loop.thisN'
p136
I0
sg29
g30
sg18
F0.4378509521484375
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p137
g24
(g52
S'\x08\x00\x00\x00'
tRp138
sg31
V
sS'external_loop.thisTrialN'
p139
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p140
I8
sS'Sessions.thisRepN'
p141
I0
sg40
g58
sS'external_loop.thisRepN'
p142
I0
sS'external_loop.thisIndex'
p143
g61
sa(dp144
g43
I2
sg15
g47
sg42
I9
sg23
g27
sS'Sessions.thisN'
p145
I9
sS'external_loop.thisN'
p146
I0
sg29
g30
sg18
F0.58407402038574219
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p147
g24
(g52
S'\t\x00\x00\x00'
tRp148
sg31
V
sS'external_loop.thisTrialN'
p149
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p150
I9
sS'Sessions.thisRepN'
p151
I0
sg40
g58
sS'external_loop.thisRepN'
p152
I0
sS'external_loop.thisIndex'
p153
g61
sa(dp154
g43
I2
sg15
g47
sg42
I10
sg23
g27
sS'Sessions.thisN'
p155
I10
sS'external_loop.thisN'
p156
I0
sg29
g30
sg18
F0.44635796546936035
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p157
g24
(g52
S'\n\x00\x00\x00'
tRp158
sg31
V
sS'external_loop.thisTrialN'
p159
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p160
I10
sS'Sessions.thisRepN'
p161
I0
sg40
g58
sS'external_loop.thisRepN'
p162
I0
sS'external_loop.thisIndex'
p163
g61
sa(dp164
g43
I2
sg15
g47
sg42
I11
sg23
g27
sS'Sessions.thisN'
p165
I11
sS'external_loop.thisN'
p166
I0
sg29
g30
sg18
F0.44301986694335938
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p167
g24
(g52
S'\x0b\x00\x00\x00'
tRp168
sg31
V
sS'external_loop.thisTrialN'
p169
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p170
I11
sS'Sessions.thisRepN'
p171
I0
sg40
g58
sS'external_loop.thisRepN'
p172
I0
sS'external_loop.thisIndex'
p173
g61
sa(dp174
g43
I1
sg15
g47
sg42
I12
sg23
g27
sS'Sessions.thisN'
p175
I12
sS'external_loop.thisN'
p176
I0
sg29
g30
sg18
F0.61692380905151367
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p177
g24
(g52
S'\x0c\x00\x00\x00'
tRp178
sg31
V
sS'external_loop.thisTrialN'
p179
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p180
I12
sS'Sessions.thisRepN'
p181
I0
sg40
g58
sS'external_loop.thisRepN'
p182
I0
sS'external_loop.thisIndex'
p183
g61
sa(dp184
g43
I2
sg15
g47
sg42
I13
sg23
g27
sS'Sessions.thisN'
p185
I13
sS'external_loop.thisN'
p186
I0
sg29
g30
sg18
F0.89301490783691406
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p187
g24
(g52
S'\r\x00\x00\x00'
tRp188
sg31
V
sS'external_loop.thisTrialN'
p189
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p190
I13
sS'Sessions.thisRepN'
p191
I0
sg40
g58
sS'external_loop.thisRepN'
p192
I0
sS'external_loop.thisIndex'
p193
g61
sa(dp194
g43
I2
sg15
g55
sg42
I14
sg23
g27
sS'Sessions.thisN'
p195
I14
sS'external_loop.thisN'
p196
I0
sg29
g30
sg18
F0.90106296539306641
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p197
g24
(g52
S'\x0e\x00\x00\x00'
tRp198
sg31
V
sS'external_loop.thisTrialN'
p199
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p200
I14
sS'Sessions.thisRepN'
p201
I0
sg40
g58
sS'external_loop.thisRepN'
p202
I0
sS'external_loop.thisIndex'
p203
g61
sa(dp204
g43
I1
sg15
g47
sg42
I15
sg23
g27
sS'Sessions.thisN'
p205
I15
sS'external_loop.thisN'
p206
I0
sg29
g30
sg18
F0.74558091163635254
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p207
g24
(g52
S'\x0f\x00\x00\x00'
tRp208
sg31
V
sS'external_loop.thisTrialN'
p209
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p210
I15
sS'Sessions.thisRepN'
p211
I0
sg40
g58
sS'external_loop.thisRepN'
p212
I0
sS'external_loop.thisIndex'
p213
g61
sa(dp214
g43
I2
sg15
g47
sg42
I16
sg23
g27
sS'Sessions.thisN'
p215
I16
sS'external_loop.thisN'
p216
I0
sg29
g30
sg18
F0.90207409858703613
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p217
g24
(g52
S'\x10\x00\x00\x00'
tRp218
sg31
V
sS'external_loop.thisTrialN'
p219
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p220
I16
sS'Sessions.thisRepN'
p221
I0
sg40
g58
sS'external_loop.thisRepN'
p222
I0
sS'external_loop.thisIndex'
p223
g61
sa(dp224
g43
I1
sg15
g47
sg42
I17
sg23
g27
sS'Sessions.thisN'
p225
I17
sS'external_loop.thisN'
p226
I0
sg29
g30
sg18
F0.87830686569213867
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p227
g24
(g52
S'\x11\x00\x00\x00'
tRp228
sg31
V
sS'external_loop.thisTrialN'
p229
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p230
I17
sS'Sessions.thisRepN'
p231
I0
sg40
g58
sS'external_loop.thisRepN'
p232
I0
sS'external_loop.thisIndex'
p233
g61
sa(dp234
g43
I2
sg15
g55
sg42
I18
sg23
g27
sS'Sessions.thisN'
p235
I18
sS'external_loop.thisN'
p236
I0
sg29
g30
sg18
F0.44805407524108887
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p237
g24
(g52
S'\x12\x00\x00\x00'
tRp238
sg31
V
sS'external_loop.thisTrialN'
p239
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p240
I18
sS'Sessions.thisRepN'
p241
I0
sg40
g58
sS'external_loop.thisRepN'
p242
I0
sS'external_loop.thisIndex'
p243
g61
sa(dp244
g43
I2
sg15
g55
sg42
I19
sg23
g27
sS'Sessions.thisN'
p245
I19
sS'external_loop.thisN'
p246
I0
sg29
g30
sg18
F0.44775915145874023
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p247
g24
(g52
S'\x13\x00\x00\x00'
tRp248
sg31
V
sS'external_loop.thisTrialN'
p249
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p250
I19
sS'Sessions.thisRepN'
p251
I0
sg40
g58
sS'external_loop.thisRepN'
p252
I0
sS'external_loop.thisIndex'
p253
g61
sa(dp254
g43
I2
sg15
g55
sg42
I20
sg23
g27
sS'Sessions.thisN'
p255
I20
sS'external_loop.thisN'
p256
I0
sg29
g30
sg18
F0.45342302322387695
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p257
g24
(g52
S'\x14\x00\x00\x00'
tRp258
sg31
V
sS'external_loop.thisTrialN'
p259
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p260
I20
sS'Sessions.thisRepN'
p261
I0
sg40
g58
sS'external_loop.thisRepN'
p262
I0
sS'external_loop.thisIndex'
p263
g61
sa(dp264
g43
I2
sg15
g47
sg42
I21
sg23
g27
sS'Sessions.thisN'
p265
I21
sS'external_loop.thisN'
p266
I0
sg29
g30
sg18
F0.59131598472595215
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p267
g24
(g52
S'\x15\x00\x00\x00'
tRp268
sg31
V
sS'external_loop.thisTrialN'
p269
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p270
I21
sS'Sessions.thisRepN'
p271
I0
sg40
g58
sS'external_loop.thisRepN'
p272
I0
sS'external_loop.thisIndex'
p273
g61
sa(dp274
g43
I1
sg15
g47
sg42
I22
sg23
g27
sS'Sessions.thisN'
p275
I22
sS'external_loop.thisN'
p276
I0
sg29
g30
sg18
F0.45208215713500977
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p277
g24
(g52
S'\x16\x00\x00\x00'
tRp278
sg31
V
sS'external_loop.thisTrialN'
p279
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p280
I22
sS'Sessions.thisRepN'
p281
I0
sg40
g58
sS'external_loop.thisRepN'
p282
I0
sS'external_loop.thisIndex'
p283
g61
sa(dp284
g43
I1
sg15
g55
sg42
I23
sg23
g27
sS'Sessions.thisN'
p285
I23
sS'external_loop.thisN'
p286
I0
sg29
g30
sg18
F0.59374690055847168
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p287
g24
(g52
S'\x17\x00\x00\x00'
tRp288
sg31
V
sS'external_loop.thisTrialN'
p289
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p290
I23
sS'Sessions.thisRepN'
p291
I0
sg40
g58
sS'external_loop.thisRepN'
p292
I0
sS'external_loop.thisIndex'
p293
g61
sa(dp294
g43
I2
sg15
g55
sg42
I24
sg23
g27
sS'Sessions.thisN'
p295
I24
sS'external_loop.thisN'
p296
I0
sg29
g30
sg18
F0.73319101333618164
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p297
g24
(g52
S'\x18\x00\x00\x00'
tRp298
sg31
V
sS'external_loop.thisTrialN'
p299
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p300
I24
sS'Sessions.thisRepN'
p301
I0
sg40
g58
sS'external_loop.thisRepN'
p302
I0
sS'external_loop.thisIndex'
p303
g61
sa(dp304
g43
I1
sg15
g55
sg42
I25
sg23
g27
sS'Sessions.thisN'
p305
I25
sS'external_loop.thisN'
p306
I0
sg29
g30
sg18
F0.89912605285644531
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p307
g24
(g52
S'\x19\x00\x00\x00'
tRp308
sg31
V
sS'external_loop.thisTrialN'
p309
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p310
I25
sS'Sessions.thisRepN'
p311
I0
sg40
g58
sS'external_loop.thisRepN'
p312
I0
sS'external_loop.thisIndex'
p313
g61
sa(dp314
g43
I1
sg15
g55
sg42
I26
sg23
g27
sS'Sessions.thisN'
p315
I26
sS'external_loop.thisN'
p316
I0
sg29
g30
sg18
F0.73443794250488281
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p317
g24
(g52
S'\x1a\x00\x00\x00'
tRp318
sg31
V
sS'external_loop.thisTrialN'
p319
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p320
I26
sS'Sessions.thisRepN'
p321
I0
sg40
g58
sS'external_loop.thisRepN'
p322
I0
sS'external_loop.thisIndex'
p323
g61
sa(dp324
g43
I1
sg15
g55
sg42
I27
sg23
g27
sS'Sessions.thisN'
p325
I27
sS'external_loop.thisN'
p326
I0
sg29
g30
sg18
F0.45515799522399902
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p327
g24
(g52
S'\x1b\x00\x00\x00'
tRp328
sg31
V
sS'external_loop.thisTrialN'
p329
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p330
I27
sS'Sessions.thisRepN'
p331
I0
sg40
g58
sS'external_loop.thisRepN'
p332
I0
sS'external_loop.thisIndex'
p333
g61
sa(dp334
g43
I2
sg15
g55
sg42
I28
sg23
g27
sS'Sessions.thisN'
p335
I28
sS'external_loop.thisN'
p336
I0
sg29
g30
sg18
F0.43838906288146973
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p337
g24
(g52
S'\x1c\x00\x00\x00'
tRp338
sg31
V
sS'external_loop.thisTrialN'
p339
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p340
I28
sS'Sessions.thisRepN'
p341
I0
sg40
g58
sS'external_loop.thisRepN'
p342
I0
sS'external_loop.thisIndex'
p343
g61
sa(dp344
g43
I1
sg15
g55
sg42
I29
sg23
g27
sS'Sessions.thisN'
p345
I29
sS'external_loop.thisN'
p346
I0
sg29
g30
sg18
F0.44779109954833984
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p347
g24
(g52
S'\x1d\x00\x00\x00'
tRp348
sg31
V
sS'external_loop.thisTrialN'
p349
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p350
I29
sS'Sessions.thisRepN'
p351
I0
sg40
g58
sS'external_loop.thisRepN'
p352
I0
sS'external_loop.thisIndex'
p353
g61
sa(dp354
g43
I1
sg15
g47
sg42
I30
sg23
g27
sS'Sessions.thisN'
p355
I30
sS'external_loop.thisN'
p356
I0
sg29
g30
sg18
F0.45060896873474121
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p357
g24
(g52
S'\x1e\x00\x00\x00'
tRp358
sg31
V
sS'external_loop.thisTrialN'
p359
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p360
I30
sS'Sessions.thisRepN'
p361
I0
sg40
g58
sS'external_loop.thisRepN'
p362
I0
sS'external_loop.thisIndex'
p363
g61
sa(dp364
g43
I1
sg15
g47
sg42
I31
sg23
g27
sS'Sessions.thisN'
p365
I31
sS'external_loop.thisN'
p366
I0
sg29
g30
sg18
F0.59968709945678711
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p367
g24
(g52
S'\x1f\x00\x00\x00'
tRp368
sg31
V
sS'external_loop.thisTrialN'
p369
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p370
I31
sS'Sessions.thisRepN'
p371
I0
sg40
g58
sS'external_loop.thisRepN'
p372
I0
sS'external_loop.thisIndex'
p373
g61
sa(dp374
g29
g30
sg43
I1
sS'Sessions.thisIndex'
p375
g24
(g52
S' \x00\x00\x00'
tRp376
sg31
V
sg15
g65
sS'external_loop.thisTrialN'
p377
I0
sg23
g27
sg42
I32
sg16
g65
sg14
g47
sS'Sessions.thisN'
p378
I32
sg41
I2
sS'external_loop.thisN'
p379
I0
sg28
g11
sg17
NsS'Sessions.thisTrialN'
p380
I32
sS'Sessions.thisRepN'
p381
I0
sg21
g22
sg40
g58
sS'external_loop.thisIndex'
p382
g61
sS'external_loop.thisRepN'
p383
I0
sa(dp384
g43
I1
sg15
g55
sg42
I33
sg23
g27
sS'Sessions.thisN'
p385
I33
sS'external_loop.thisN'
p386
I0
sg29
g30
sg18
F0.5901038646697998
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p387
g24
(g52
S'!\x00\x00\x00'
tRp388
sg31
V
sS'external_loop.thisTrialN'
p389
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p390
I33
sS'Sessions.thisRepN'
p391
I0
sg40
g58
sS'external_loop.thisRepN'
p392
I0
sS'external_loop.thisIndex'
p393
g61
sa(dp394
g43
I1
sg15
g47
sg42
I34
sg23
g27
sS'Sessions.thisN'
p395
I34
sS'external_loop.thisN'
p396
I0
sg29
g30
sg18
F1.6180238723754883
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p397
g24
(g52
S'"\x00\x00\x00'
tRp398
sg31
V
sS'external_loop.thisTrialN'
p399
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p400
I34
sS'Sessions.thisRepN'
p401
I0
sg40
g58
sS'external_loop.thisRepN'
p402
I0
sS'external_loop.thisIndex'
p403
g61
sa(dp404
g43
I2
sg15
g55
sg42
I35
sg23
g27
sS'Sessions.thisN'
p405
I35
sS'external_loop.thisN'
p406
I0
sg29
g30
sg18
F0.43337583541870117
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p407
g24
(g52
S'#\x00\x00\x00'
tRp408
sg31
V
sS'external_loop.thisTrialN'
p409
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p410
I35
sS'Sessions.thisRepN'
p411
I0
sg40
g58
sS'external_loop.thisRepN'
p412
I0
sS'external_loop.thisIndex'
p413
g61
sa(dp414
g43
I2
sg15
g55
sg42
I36
sg23
g27
sS'Sessions.thisN'
p415
I36
sS'external_loop.thisN'
p416
I0
sg29
g30
sg18
F0.88073396682739258
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p417
g24
(g52
S'$\x00\x00\x00'
tRp418
sg31
V
sS'external_loop.thisTrialN'
p419
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p420
I36
sS'Sessions.thisRepN'
p421
I0
sg40
g58
sS'external_loop.thisRepN'
p422
I0
sS'external_loop.thisIndex'
p423
g61
sa(dp424
g43
I1
sg15
g47
sg42
I37
sg23
g27
sS'Sessions.thisN'
p425
I37
sS'external_loop.thisN'
p426
I0
sg29
g30
sg18
F0.61061787605285645
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p427
g24
(g52
S'%\x00\x00\x00'
tRp428
sg31
V
sS'external_loop.thisTrialN'
p429
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p430
I37
sS'Sessions.thisRepN'
p431
I0
sg40
g58
sS'external_loop.thisRepN'
p432
I0
sS'external_loop.thisIndex'
p433
g61
sa(dp434
g43
I1
sg15
g55
sg42
I38
sg23
g27
sS'Sessions.thisN'
p435
I38
sS'external_loop.thisN'
p436
I0
sg29
g30
sg18
F0.44725489616394043
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p437
g24
(g52
S'&\x00\x00\x00'
tRp438
sg31
V
sS'external_loop.thisTrialN'
p439
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p440
I38
sS'Sessions.thisRepN'
p441
I0
sg40
g58
sS'external_loop.thisRepN'
p442
I0
sS'external_loop.thisIndex'
p443
g61
sa(dp444
g29
g30
sg43
I2
sS'Sessions.thisIndex'
p445
g24
(g52
S"'\x00\x00\x00"
tRp446
sg31
V
sg15
g65
sS'external_loop.thisTrialN'
p447
I0
sg23
g27
sg42
I39
sg16
g65
sg14
g55
sS'Sessions.thisN'
p448
I39
sg41
I1
sS'external_loop.thisN'
p449
I0
sg28
g11
sg17
NsS'Sessions.thisTrialN'
p450
I39
sS'Sessions.thisRepN'
p451
I0
sg21
g22
sg40
g58
sS'external_loop.thisIndex'
p452
g61
sS'external_loop.thisRepN'
p453
I0
sa(dp454
g43
I1
sg15
g47
sg42
I40
sg23
g27
sS'Sessions.thisN'
p455
I40
sS'external_loop.thisN'
p456
I0
sg29
g30
sg18
F0.74905800819396973
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p457
g24
(g52
S'(\x00\x00\x00'
tRp458
sg31
V
sS'external_loop.thisTrialN'
p459
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p460
I40
sS'Sessions.thisRepN'
p461
I0
sg40
g58
sS'external_loop.thisRepN'
p462
I0
sS'external_loop.thisIndex'
p463
g61
sa(dp464
g43
I1
sg15
g47
sg42
I41
sg23
g27
sS'Sessions.thisN'
p465
I41
sS'external_loop.thisN'
p466
I0
sg29
g30
sg18
F1.045551061630249
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p467
g24
(g52
S')\x00\x00\x00'
tRp468
sg31
V
sS'external_loop.thisTrialN'
p469
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p470
I41
sS'Sessions.thisRepN'
p471
I0
sg40
g58
sS'external_loop.thisRepN'
p472
I0
sS'external_loop.thisIndex'
p473
g61
sa(dp474
g43
I2
sg15
g47
sg42
I42
sg23
g27
sS'Sessions.thisN'
p475
I42
sS'external_loop.thisN'
p476
I0
sg29
g30
sg18
F0.76681995391845703
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p477
g24
(g52
S'*\x00\x00\x00'
tRp478
sg31
V
sS'external_loop.thisTrialN'
p479
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p480
I42
sS'Sessions.thisRepN'
p481
I0
sg40
g58
sS'external_loop.thisRepN'
p482
I0
sS'external_loop.thisIndex'
p483
g61
sa(dp484
g43
I2
sg15
g47
sg42
I43
sg23
g27
sS'Sessions.thisN'
p485
I43
sS'external_loop.thisN'
p486
I0
sg29
g30
sg18
F0.45256710052490234
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p487
g24
(g52
S'+\x00\x00\x00'
tRp488
sg31
V
sS'external_loop.thisTrialN'
p489
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p490
I43
sS'Sessions.thisRepN'
p491
I0
sg40
g58
sS'external_loop.thisRepN'
p492
I0
sS'external_loop.thisIndex'
p493
g61
sa(dp494
g43
I1
sg15
g55
sg42
I44
sg23
g27
sS'Sessions.thisN'
p495
I44
sS'external_loop.thisN'
p496
I0
sg29
g30
sg18
F0.45003390312194824
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p497
g24
(g52
S',\x00\x00\x00'
tRp498
sg31
V
sS'external_loop.thisTrialN'
p499
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p500
I44
sS'Sessions.thisRepN'
p501
I0
sg40
g58
sS'external_loop.thisRepN'
p502
I0
sS'external_loop.thisIndex'
p503
g61
sa(dp504
g29
g30
sg43
I1
sS'Sessions.thisIndex'
p505
g24
(g52
S'-\x00\x00\x00'
tRp506
sg31
V
sg15
g65
sS'external_loop.thisTrialN'
p507
I0
sg23
g27
sg42
I45
sg16
g65
sg14
g47
sS'Sessions.thisN'
p508
I45
sg41
I2
sS'external_loop.thisN'
p509
I0
sg28
g11
sg17
NsS'Sessions.thisTrialN'
p510
I45
sS'Sessions.thisRepN'
p511
I0
sg21
g22
sg40
g58
sS'external_loop.thisIndex'
p512
g61
sS'external_loop.thisRepN'
p513
I0
sa(dp514
g43
I1
sg15
g55
sg42
I46
sg23
g27
sS'Sessions.thisN'
p515
I46
sS'external_loop.thisN'
p516
I0
sg29
g30
sg18
F1.9247379302978516
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p517
g24
(g52
S'.\x00\x00\x00'
tRp518
sg31
V
sS'external_loop.thisTrialN'
p519
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p520
I46
sS'Sessions.thisRepN'
p521
I0
sg40
g58
sS'external_loop.thisRepN'
p522
I0
sS'external_loop.thisIndex'
p523
g61
sa(dp524
g43
I2
sg15
g55
sg42
I47
sg23
g27
sS'Sessions.thisN'
p525
I47
sS'external_loop.thisN'
p526
I0
sg29
g30
sg18
F0.90355706214904785
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p527
g24
(g52
S'/\x00\x00\x00'
tRp528
sg31
V
sS'external_loop.thisTrialN'
p529
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p530
I47
sS'Sessions.thisRepN'
p531
I0
sg40
g58
sS'external_loop.thisRepN'
p532
I0
sS'external_loop.thisIndex'
p533
g61
sa(dp534
g43
I2
sg15
g47
sg42
I48
sg23
g27
sS'Sessions.thisN'
p535
I48
sS'external_loop.thisN'
p536
I0
sg29
g30
sg18
F1.3432090282440186
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p537
g24
(g52
S'0\x00\x00\x00'
tRp538
sg31
V
sS'external_loop.thisTrialN'
p539
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p540
I48
sS'Sessions.thisRepN'
p541
I0
sg40
g58
sS'external_loop.thisRepN'
p542
I0
sS'external_loop.thisIndex'
p543
g61
sa(dp544
g43
I2
sg15
g47
sg42
I49
sg23
g27
sS'Sessions.thisN'
p545
I49
sS'external_loop.thisN'
p546
I0
sg29
g30
sg18
F0.5919640064239502
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p547
g24
(g52
S'1\x00\x00\x00'
tRp548
sg31
V
sS'external_loop.thisTrialN'
p549
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p550
I49
sS'Sessions.thisRepN'
p551
I0
sg40
g58
sS'external_loop.thisRepN'
p552
I0
sS'external_loop.thisIndex'
p553
g61
sa(dp554
g43
I2
sg15
g47
sg42
I50
sg23
g27
sS'Sessions.thisN'
p555
I50
sS'external_loop.thisN'
p556
I0
sg29
g30
sg18
F0.5952908992767334
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p557
g24
(g52
S'2\x00\x00\x00'
tRp558
sg31
V
sS'external_loop.thisTrialN'
p559
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p560
I50
sS'Sessions.thisRepN'
p561
I0
sg40
g58
sS'external_loop.thisRepN'
p562
I0
sS'external_loop.thisIndex'
p563
g61
sa(dp564
g43
I1
sg15
g47
sg42
I51
sg23
g27
sS'Sessions.thisN'
p565
I51
sS'external_loop.thisN'
p566
I0
sg29
g30
sg18
F0.15207791328430176
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p567
g24
(g52
S'3\x00\x00\x00'
tRp568
sg31
V
sS'external_loop.thisTrialN'
p569
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p570
I51
sS'Sessions.thisRepN'
p571
I0
sg40
g58
sS'external_loop.thisRepN'
p572
I0
sS'external_loop.thisIndex'
p573
g61
sa(dp574
g43
I2
sg15
g47
sg42
I52
sg23
g27
sS'Sessions.thisN'
p575
I52
sS'external_loop.thisN'
p576
I0
sg29
g30
sg18
F0.92181491851806641
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p577
g24
(g52
S'4\x00\x00\x00'
tRp578
sg31
V
sS'external_loop.thisTrialN'
p579
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p580
I52
sS'Sessions.thisRepN'
p581
I0
sg40
g58
sS'external_loop.thisRepN'
p582
I0
sS'external_loop.thisIndex'
p583
g61
sa(dp584
g43
I1
sg15
g47
sg42
I53
sg23
g27
sS'Sessions.thisN'
p585
I53
sS'external_loop.thisN'
p586
I0
sg29
g30
sg18
F0.60292601585388184
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p587
g24
(g52
S'5\x00\x00\x00'
tRp588
sg31
V
sS'external_loop.thisTrialN'
p589
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p590
I53
sS'Sessions.thisRepN'
p591
I0
sg40
g58
sS'external_loop.thisRepN'
p592
I0
sS'external_loop.thisIndex'
p593
g61
sa(dp594
g43
I2
sg15
g55
sg42
I54
sg23
g27
sS'Sessions.thisN'
p595
I54
sS'external_loop.thisN'
p596
I0
sg29
g30
sg18
F0.14573001861572266
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p597
g24
(g52
S'6\x00\x00\x00'
tRp598
sg31
V
sS'external_loop.thisTrialN'
p599
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p600
I54
sS'Sessions.thisRepN'
p601
I0
sg40
g58
sS'external_loop.thisRepN'
p602
I0
sS'external_loop.thisIndex'
p603
g61
sa(dp604
g43
I2
sg15
g47
sg42
I55
sg23
g27
sS'Sessions.thisN'
p605
I55
sS'external_loop.thisN'
p606
I0
sg29
g30
sg18
F1.0650990009307861
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p607
g24
(g52
S'7\x00\x00\x00'
tRp608
sg31
V
sS'external_loop.thisTrialN'
p609
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p610
I55
sS'Sessions.thisRepN'
p611
I0
sg40
g58
sS'external_loop.thisRepN'
p612
I0
sS'external_loop.thisIndex'
p613
g61
sa(dp614
g43
I2
sg15
g47
sg42
I56
sg23
g27
sS'Sessions.thisN'
p615
I56
sS'external_loop.thisN'
p616
I0
sg29
g30
sg18
F0.44917798042297363
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p617
g24
(g52
S'8\x00\x00\x00'
tRp618
sg31
V
sS'external_loop.thisTrialN'
p619
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p620
I56
sS'Sessions.thisRepN'
p621
I0
sg40
g58
sS'external_loop.thisRepN'
p622
I0
sS'external_loop.thisIndex'
p623
g61
sa(dp624
g43
I1
sg15
g47
sg42
I57
sg23
g27
sS'Sessions.thisN'
p625
I57
sS'external_loop.thisN'
p626
I0
sg29
g30
sg18
F0.74725604057312012
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p627
g24
(g52
S'9\x00\x00\x00'
tRp628
sg31
V
sS'external_loop.thisTrialN'
p629
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p630
I57
sS'Sessions.thisRepN'
p631
I0
sg40
g58
sS'external_loop.thisRepN'
p632
I0
sS'external_loop.thisIndex'
p633
g61
sa(dp634
g43
I2
sg15
g47
sg42
I58
sg23
g27
sS'Sessions.thisN'
p635
I58
sS'external_loop.thisN'
p636
I0
sg29
g30
sg18
F0.59827280044555664
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p637
g24
(g52
S':\x00\x00\x00'
tRp638
sg31
V
sS'external_loop.thisTrialN'
p639
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p640
I58
sS'Sessions.thisRepN'
p641
I0
sg40
g58
sS'external_loop.thisRepN'
p642
I0
sS'external_loop.thisIndex'
p643
g61
sa(dp644
g43
I2
sg15
g47
sg42
I59
sg23
g27
sS'Sessions.thisN'
p645
I59
sS'external_loop.thisN'
p646
I0
sg29
g30
sg18
F0.90884184837341309
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p647
g24
(g52
S';\x00\x00\x00'
tRp648
sg31
V
sS'external_loop.thisTrialN'
p649
I0
sg14
g55
sg41
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p650
I59
sS'Sessions.thisRepN'
p651
I0
sg40
g58
sS'external_loop.thisRepN'
p652
I0
sS'external_loop.thisIndex'
p653
g61
sa(dp654
g43
I1
sg15
g47
sg42
I60
sg23
g27
sS'Sessions.thisN'
p655
I60
sS'external_loop.thisN'
p656
I0
sg29
g30
sg18
F0.75017905235290527
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p657
g24
(g52
S'<\x00\x00\x00'
tRp658
sg31
V
sS'external_loop.thisTrialN'
p659
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p660
I60
sS'Sessions.thisRepN'
p661
I0
sg40
g58
sS'external_loop.thisRepN'
p662
I0
sS'external_loop.thisIndex'
p663
g61
sa(dp664
g43
I1
sg15
g47
sg42
I61
sg23
g27
sS'Sessions.thisN'
p665
I61
sS'external_loop.thisN'
p666
I0
sg29
g30
sg18
F0.30295491218566895
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p667
g24
(g52
S'=\x00\x00\x00'
tRp668
sg31
V
sS'external_loop.thisTrialN'
p669
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p670
I61
sS'Sessions.thisRepN'
p671
I0
sg40
g58
sS'external_loop.thisRepN'
p672
I0
sS'external_loop.thisIndex'
p673
g61
sa(dp674
g43
I1
sg15
g55
sg42
I62
sg23
g27
sS'Sessions.thisN'
p675
I62
sS'external_loop.thisN'
p676
I0
sg29
g30
sg18
F0.44069910049438477
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p677
g24
(g52
S'>\x00\x00\x00'
tRp678
sg31
V
sS'external_loop.thisTrialN'
p679
I0
sg14
g47
sg41
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p680
I62
sS'Sessions.thisRepN'
p681
I0
sg40
g58
sS'external_loop.thisRepN'
p682
I0
sS'external_loop.thisIndex'
p683
g61
sa(dp684
g29
g30
sg31
V
sS'external_loop.thisTrialN'
p685
I0
sg23
g27
sS'external_loop.thisN'
p686
I0
sg28
g11
sg21
g22
sg40
g58
sS'external_loop.thisRepN'
p687
I0
sS'external_loop.thisIndex'
p688
g61
sa(dp689
Vcom_result_pool
p690
I2
sg15
g47
sVcom_condi
p691
I0
sg23
g27
sS'Sessions.thisN'
p692
I0
sS'external_loop.thisN'
p693
I1
sg29
g30
sg18
F1.3533239364624023
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p694
g24
(g52
S'\x00\x00\x00\x00'
tRp695
sg31
V
sS'external_loop.thisTrialN'
p696
I1
sg14
g47
sVcom_result_pool_s2
p697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p698
I0
sS'Sessions.thisRepN'
p699
I0
sg40
Vs2
p700
sS'external_loop.thisRepN'
p701
I0
sS'external_loop.thisIndex'
p702
g24
(g52
S'\x01\x00\x00\x00'
tRp703
sa(dp704
g690
I1
sg15
g47
sg691
I1
sg23
g27
sS'Sessions.thisN'
p705
I1
sS'external_loop.thisN'
p706
I1
sg29
g30
sg18
F0.59757900238037109
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p707
g24
(g52
S'\x01\x00\x00\x00'
tRp708
sg31
V
sS'external_loop.thisTrialN'
p709
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p710
I1
sS'Sessions.thisRepN'
p711
I0
sg40
g700
sS'external_loop.thisRepN'
p712
I0
sS'external_loop.thisIndex'
p713
g703
sa(dp714
g690
I1
sg15
g55
sg691
I2
sg23
g27
sS'Sessions.thisN'
p715
I2
sS'external_loop.thisN'
p716
I1
sg29
g30
sg18
F0.60604596138000488
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p717
g24
(g52
S'\x02\x00\x00\x00'
tRp718
sg31
V
sS'external_loop.thisTrialN'
p719
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p720
I2
sS'Sessions.thisRepN'
p721
I0
sg40
g700
sS'external_loop.thisRepN'
p722
I0
sS'external_loop.thisIndex'
p723
g703
sa(dp724
g690
I2
sg15
g55
sg691
I3
sg23
g27
sS'Sessions.thisN'
p725
I3
sS'external_loop.thisN'
p726
I1
sg29
g30
sg18
F0.45018720626831055
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p727
g24
(g52
S'\x03\x00\x00\x00'
tRp728
sg31
V
sS'external_loop.thisTrialN'
p729
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p730
I3
sS'Sessions.thisRepN'
p731
I0
sg40
g700
sS'external_loop.thisRepN'
p732
I0
sS'external_loop.thisIndex'
p733
g703
sa(dp734
g690
I1
sg15
g47
sg691
I4
sg23
g27
sS'Sessions.thisN'
p735
I4
sS'external_loop.thisN'
p736
I1
sg29
g30
sg18
F0.59997797012329102
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p737
g24
(g52
S'\x04\x00\x00\x00'
tRp738
sg31
V
sS'external_loop.thisTrialN'
p739
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p740
I4
sS'Sessions.thisRepN'
p741
I0
sg40
g700
sS'external_loop.thisRepN'
p742
I0
sS'external_loop.thisIndex'
p743
g703
sa(dp744
g690
I2
sg15
g55
sg691
I5
sg23
g27
sS'Sessions.thisN'
p745
I5
sS'external_loop.thisN'
p746
I1
sg29
g30
sg18
F0.46318888664245605
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p747
g24
(g52
S'\x05\x00\x00\x00'
tRp748
sg31
V
sS'external_loop.thisTrialN'
p749
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p750
I5
sS'Sessions.thisRepN'
p751
I0
sg40
g700
sS'external_loop.thisRepN'
p752
I0
sS'external_loop.thisIndex'
p753
g703
sa(dp754
g690
I1
sg15
g55
sg691
I6
sg23
g27
sS'Sessions.thisN'
p755
I6
sS'external_loop.thisN'
p756
I1
sg29
g30
sg18
F0.59972500801086426
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p757
g24
(g52
S'\x06\x00\x00\x00'
tRp758
sg31
V
sS'external_loop.thisTrialN'
p759
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p760
I6
sS'Sessions.thisRepN'
p761
I0
sg40
g700
sS'external_loop.thisRepN'
p762
I0
sS'external_loop.thisIndex'
p763
g703
sa(dp764
g690
I2
sg15
g55
sg691
I7
sg23
g27
sS'Sessions.thisN'
p765
I7
sS'external_loop.thisN'
p766
I1
sg29
g30
sg18
F0.45194220542907715
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p767
g24
(g52
S'\x07\x00\x00\x00'
tRp768
sg31
V
sS'external_loop.thisTrialN'
p769
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p770
I7
sS'Sessions.thisRepN'
p771
I0
sg40
g700
sS'external_loop.thisRepN'
p772
I0
sS'external_loop.thisIndex'
p773
g703
sa(dp774
g690
I2
sg15
g47
sg691
I8
sg23
g27
sS'Sessions.thisN'
p775
I8
sS'external_loop.thisN'
p776
I1
sg29
g30
sg18
F0.45076799392700195
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p777
g24
(g52
S'\x08\x00\x00\x00'
tRp778
sg31
V
sS'external_loop.thisTrialN'
p779
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p780
I8
sS'Sessions.thisRepN'
p781
I0
sg40
g700
sS'external_loop.thisRepN'
p782
I0
sS'external_loop.thisIndex'
p783
g703
sa(dp784
g690
I2
sg15
g47
sg691
I9
sg23
g27
sS'Sessions.thisN'
p785
I9
sS'external_loop.thisN'
p786
I1
sg29
g30
sg18
F0.45003008842468262
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p787
g24
(g52
S'\t\x00\x00\x00'
tRp788
sg31
V
sS'external_loop.thisTrialN'
p789
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p790
I9
sS'Sessions.thisRepN'
p791
I0
sg40
g700
sS'external_loop.thisRepN'
p792
I0
sS'external_loop.thisIndex'
p793
g703
sa(dp794
g690
I2
sg15
g55
sg691
I10
sg23
g27
sS'Sessions.thisN'
p795
I10
sS'external_loop.thisN'
p796
I1
sg29
g30
sg18
F0.45036602020263672
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p797
g24
(g52
S'\n\x00\x00\x00'
tRp798
sg31
V
sS'external_loop.thisTrialN'
p799
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p800
I10
sS'Sessions.thisRepN'
p801
I0
sg40
g700
sS'external_loop.thisRepN'
p802
I0
sS'external_loop.thisIndex'
p803
g703
sa(dp804
g690
I2
sg15
g55
sg691
I11
sg23
g27
sS'Sessions.thisN'
p805
I11
sS'external_loop.thisN'
p806
I1
sg29
g30
sg18
F0.59193706512451172
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p807
g24
(g52
S'\x0b\x00\x00\x00'
tRp808
sg31
V
sS'external_loop.thisTrialN'
p809
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p810
I11
sS'Sessions.thisRepN'
p811
I0
sg40
g700
sS'external_loop.thisRepN'
p812
I0
sS'external_loop.thisIndex'
p813
g703
sa(dp814
g690
I1
sg15
g55
sg691
I12
sg23
g27
sS'Sessions.thisN'
p815
I12
sS'external_loop.thisN'
p816
I1
sg29
g30
sg18
F0.7365419864654541
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p817
g24
(g52
S'\x0c\x00\x00\x00'
tRp818
sg31
V
sS'external_loop.thisTrialN'
p819
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p820
I12
sS'Sessions.thisRepN'
p821
I0
sg40
g700
sS'external_loop.thisRepN'
p822
I0
sS'external_loop.thisIndex'
p823
g703
sa(dp824
g690
I2
sg15
g55
sg691
I13
sg23
g27
sS'Sessions.thisN'
p825
I13
sS'external_loop.thisN'
p826
I1
sg29
g30
sg18
F0.44965720176696777
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p827
g24
(g52
S'\r\x00\x00\x00'
tRp828
sg31
V
sS'external_loop.thisTrialN'
p829
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p830
I13
sS'Sessions.thisRepN'
p831
I0
sg40
g700
sS'external_loop.thisRepN'
p832
I0
sS'external_loop.thisIndex'
p833
g703
sa(dp834
g690
I2
sg15
g55
sg691
I14
sg23
g27
sS'Sessions.thisN'
p835
I14
sS'external_loop.thisN'
p836
I1
sg29
g30
sg18
F0.44369101524353027
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p837
g24
(g52
S'\x0e\x00\x00\x00'
tRp838
sg31
V
sS'external_loop.thisTrialN'
p839
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p840
I14
sS'Sessions.thisRepN'
p841
I0
sg40
g700
sS'external_loop.thisRepN'
p842
I0
sS'external_loop.thisIndex'
p843
g703
sa(dp844
g690
I1
sg15
g55
sg691
I15
sg23
g27
sS'Sessions.thisN'
p845
I15
sS'external_loop.thisN'
p846
I1
sg29
g30
sg18
F0.45263791084289551
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p847
g24
(g52
S'\x0f\x00\x00\x00'
tRp848
sg31
V
sS'external_loop.thisTrialN'
p849
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p850
I15
sS'Sessions.thisRepN'
p851
I0
sg40
g700
sS'external_loop.thisRepN'
p852
I0
sS'external_loop.thisIndex'
p853
g703
sa(dp854
g690
I2
sg15
g55
sg691
I16
sg23
g27
sS'Sessions.thisN'
p855
I16
sS'external_loop.thisN'
p856
I1
sg29
g30
sg18
F0.60107898712158203
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p857
g24
(g52
S'\x10\x00\x00\x00'
tRp858
sg31
V
sS'external_loop.thisTrialN'
p859
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p860
I16
sS'Sessions.thisRepN'
p861
I0
sg40
g700
sS'external_loop.thisRepN'
p862
I0
sS'external_loop.thisIndex'
p863
g703
sa(dp864
g690
I1
sg15
g55
sg691
I17
sg23
g27
sS'Sessions.thisN'
p865
I17
sS'external_loop.thisN'
p866
I1
sg29
g30
sg18
F0.45425105094909668
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p867
g24
(g52
S'\x11\x00\x00\x00'
tRp868
sg31
V
sS'external_loop.thisTrialN'
p869
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p870
I17
sS'Sessions.thisRepN'
p871
I0
sg40
g700
sS'external_loop.thisRepN'
p872
I0
sS'external_loop.thisIndex'
p873
g703
sa(dp874
g690
I2
sg15
g55
sg691
I18
sg23
g27
sS'Sessions.thisN'
p875
I18
sS'external_loop.thisN'
p876
I1
sg29
g30
sg18
F0.45163106918334961
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p877
g24
(g52
S'\x12\x00\x00\x00'
tRp878
sg31
V
sS'external_loop.thisTrialN'
p879
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p880
I18
sS'Sessions.thisRepN'
p881
I0
sg40
g700
sS'external_loop.thisRepN'
p882
I0
sS'external_loop.thisIndex'
p883
g703
sa(dp884
g690
I2
sg15
g55
sg691
I19
sg23
g27
sS'Sessions.thisN'
p885
I19
sS'external_loop.thisN'
p886
I1
sg29
g30
sg18
F0.60929107666015625
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p887
g24
(g52
S'\x13\x00\x00\x00'
tRp888
sg31
V
sS'external_loop.thisTrialN'
p889
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p890
I19
sS'Sessions.thisRepN'
p891
I0
sg40
g700
sS'external_loop.thisRepN'
p892
I0
sS'external_loop.thisIndex'
p893
g703
sa(dp894
g690
I2
sg15
g47
sg691
I20
sg23
g27
sS'Sessions.thisN'
p895
I20
sS'external_loop.thisN'
p896
I1
sg29
g30
sg18
F0.45137405395507812
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p897
g24
(g52
S'\x14\x00\x00\x00'
tRp898
sg31
V
sS'external_loop.thisTrialN'
p899
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p900
I20
sS'Sessions.thisRepN'
p901
I0
sg40
g700
sS'external_loop.thisRepN'
p902
I0
sS'external_loop.thisIndex'
p903
g703
sa(dp904
g690
I2
sg15
g47
sg691
I21
sg23
g27
sS'Sessions.thisN'
p905
I21
sS'external_loop.thisN'
p906
I1
sg29
g30
sg18
F0.75337100028991699
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p907
g24
(g52
S'\x15\x00\x00\x00'
tRp908
sg31
V
sS'external_loop.thisTrialN'
p909
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p910
I21
sS'Sessions.thisRepN'
p911
I0
sg40
g700
sS'external_loop.thisRepN'
p912
I0
sS'external_loop.thisIndex'
p913
g703
sa(dp914
g690
I1
sg15
g55
sg691
I22
sg23
g27
sS'Sessions.thisN'
p915
I22
sS'external_loop.thisN'
p916
I1
sg29
g30
sg18
F0.59991717338562012
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p917
g24
(g52
S'\x16\x00\x00\x00'
tRp918
sg31
V
sS'external_loop.thisTrialN'
p919
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p920
I22
sS'Sessions.thisRepN'
p921
I0
sg40
g700
sS'external_loop.thisRepN'
p922
I0
sS'external_loop.thisIndex'
p923
g703
sa(dp924
g690
I1
sg15
g55
sg691
I23
sg23
g27
sS'Sessions.thisN'
p925
I23
sS'external_loop.thisN'
p926
I1
sg29
g30
sg18
F0.59880995750427246
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p927
g24
(g52
S'\x17\x00\x00\x00'
tRp928
sg31
V
sS'external_loop.thisTrialN'
p929
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p930
I23
sS'Sessions.thisRepN'
p931
I0
sg40
g700
sS'external_loop.thisRepN'
p932
I0
sS'external_loop.thisIndex'
p933
g703
sa(dp934
g690
I2
sg15
g47
sg691
I24
sg23
g27
sS'Sessions.thisN'
p935
I24
sS'external_loop.thisN'
p936
I1
sg29
g30
sg18
F0.75811219215393066
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p937
g24
(g52
S'\x18\x00\x00\x00'
tRp938
sg31
V
sS'external_loop.thisTrialN'
p939
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p940
I24
sS'Sessions.thisRepN'
p941
I0
sg40
g700
sS'external_loop.thisRepN'
p942
I0
sS'external_loop.thisIndex'
p943
g703
sa(dp944
g690
I1
sg15
g55
sg691
I25
sg23
g27
sS'Sessions.thisN'
p945
I25
sS'external_loop.thisN'
p946
I1
sg29
g30
sg18
F0.59723997116088867
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p947
g24
(g52
S'\x19\x00\x00\x00'
tRp948
sg31
V
sS'external_loop.thisTrialN'
p949
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p950
I25
sS'Sessions.thisRepN'
p951
I0
sg40
g700
sS'external_loop.thisRepN'
p952
I0
sS'external_loop.thisIndex'
p953
g703
sa(dp954
g690
I1
sg15
g47
sg691
I26
sg23
g27
sS'Sessions.thisN'
p955
I26
sS'external_loop.thisN'
p956
I1
sg29
g30
sg18
F0.45638179779052734
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p957
g24
(g52
S'\x1a\x00\x00\x00'
tRp958
sg31
V
sS'external_loop.thisTrialN'
p959
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p960
I26
sS'Sessions.thisRepN'
p961
I0
sg40
g700
sS'external_loop.thisRepN'
p962
I0
sS'external_loop.thisIndex'
p963
g703
sa(dp964
g690
I1
sg15
g55
sg691
I27
sg23
g27
sS'Sessions.thisN'
p965
I27
sS'external_loop.thisN'
p966
I1
sg29
g30
sg18
F0.45491909980773926
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p967
g24
(g52
S'\x1b\x00\x00\x00'
tRp968
sg31
V
sS'external_loop.thisTrialN'
p969
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p970
I27
sS'Sessions.thisRepN'
p971
I0
sg40
g700
sS'external_loop.thisRepN'
p972
I0
sS'external_loop.thisIndex'
p973
g703
sa(dp974
g690
I2
sg15
g55
sg691
I28
sg23
g27
sS'Sessions.thisN'
p975
I28
sS'external_loop.thisN'
p976
I1
sg29
g30
sg18
F0.45943403244018555
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p977
g24
(g52
S'\x1c\x00\x00\x00'
tRp978
sg31
V
sS'external_loop.thisTrialN'
p979
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p980
I28
sS'Sessions.thisRepN'
p981
I0
sg40
g700
sS'external_loop.thisRepN'
p982
I0
sS'external_loop.thisIndex'
p983
g703
sa(dp984
g690
I1
sg15
g47
sg691
I29
sg23
g27
sS'Sessions.thisN'
p985
I29
sS'external_loop.thisN'
p986
I1
sg29
g30
sg18
F0.44865012168884277
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p987
g24
(g52
S'\x1d\x00\x00\x00'
tRp988
sg31
V
sS'external_loop.thisTrialN'
p989
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p990
I29
sS'Sessions.thisRepN'
p991
I0
sg40
g700
sS'external_loop.thisRepN'
p992
I0
sS'external_loop.thisIndex'
p993
g703
sa(dp994
g690
I1
sg15
g47
sg691
I30
sg23
g27
sS'Sessions.thisN'
p995
I30
sS'external_loop.thisN'
p996
I1
sg29
g30
sg18
F0.30180001258850098
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p997
g24
(g52
S'\x1e\x00\x00\x00'
tRp998
sg31
V
sS'external_loop.thisTrialN'
p999
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p1000
I30
sS'Sessions.thisRepN'
p1001
I0
sg40
g700
sS'external_loop.thisRepN'
p1002
I0
sS'external_loop.thisIndex'
p1003
g703
sa(dp1004
g690
I1
sg15
g47
sg691
I31
sg23
g27
sS'Sessions.thisN'
p1005
I31
sS'external_loop.thisN'
p1006
I1
sg29
g30
sg18
F0.45909309387207031
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1007
g24
(g52
S'\x1f\x00\x00\x00'
tRp1008
sg31
V
sS'external_loop.thisTrialN'
p1009
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p1010
I31
sS'Sessions.thisRepN'
p1011
I0
sg40
g700
sS'external_loop.thisRepN'
p1012
I0
sS'external_loop.thisIndex'
p1013
g703
sa(dp1014
g690
I1
sg15
g47
sg691
I32
sg23
g27
sS'Sessions.thisN'
p1015
I32
sS'external_loop.thisN'
p1016
I1
sg29
g30
sg18
F0.45621609687805176
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1017
g24
(g52
S' \x00\x00\x00'
tRp1018
sg31
V
sS'external_loop.thisTrialN'
p1019
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1020
I32
sS'Sessions.thisRepN'
p1021
I0
sg40
g700
sS'external_loop.thisRepN'
p1022
I0
sS'external_loop.thisIndex'
p1023
g703
sa(dp1024
g690
I1
sg15
g47
sg691
I33
sg23
g27
sS'Sessions.thisN'
p1025
I33
sS'external_loop.thisN'
p1026
I1
sg29
g30
sg18
F0.61620903015136719
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1027
g24
(g52
S'!\x00\x00\x00'
tRp1028
sg31
V
sS'external_loop.thisTrialN'
p1029
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1030
I33
sS'Sessions.thisRepN'
p1031
I0
sg40
g700
sS'external_loop.thisRepN'
p1032
I0
sS'external_loop.thisIndex'
p1033
g703
sa(dp1034
g690
I1
sg15
g47
sg691
I34
sg23
g27
sS'Sessions.thisN'
p1035
I34
sS'external_loop.thisN'
p1036
I1
sg29
g30
sg18
F0.7651069164276123
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1037
g24
(g52
S'"\x00\x00\x00'
tRp1038
sg31
V
sS'external_loop.thisTrialN'
p1039
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p1040
I34
sS'Sessions.thisRepN'
p1041
I0
sg40
g700
sS'external_loop.thisRepN'
p1042
I0
sS'external_loop.thisIndex'
p1043
g703
sa(dp1044
g690
I2
sg15
g47
sg691
I35
sg23
g27
sS'Sessions.thisN'
p1045
I35
sS'external_loop.thisN'
p1046
I1
sg29
g30
sg18
F0.46077489852905273
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p1047
g24
(g52
S'#\x00\x00\x00'
tRp1048
sg31
V
sS'external_loop.thisTrialN'
p1049
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1050
I35
sS'Sessions.thisRepN'
p1051
I0
sg40
g700
sS'external_loop.thisRepN'
p1052
I0
sS'external_loop.thisIndex'
p1053
g703
sa(dp1054
g690
I2
sg15
g55
sg691
I36
sg23
g27
sS'Sessions.thisN'
p1055
I36
sS'external_loop.thisN'
p1056
I1
sg29
g30
sg18
F0.59923100471496582
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1057
g24
(g52
S'$\x00\x00\x00'
tRp1058
sg31
V
sS'external_loop.thisTrialN'
p1059
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1060
I36
sS'Sessions.thisRepN'
p1061
I0
sg40
g700
sS'external_loop.thisRepN'
p1062
I0
sS'external_loop.thisIndex'
p1063
g703
sa(dp1064
g690
I1
sg15
g47
sg691
I37
sg23
g27
sS'Sessions.thisN'
p1065
I37
sS'external_loop.thisN'
p1066
I1
sg29
g30
sg18
F0.91802716255187988
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1067
g24
(g52
S'%\x00\x00\x00'
tRp1068
sg31
V
sS'external_loop.thisTrialN'
p1069
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1070
I37
sS'Sessions.thisRepN'
p1071
I0
sg40
g700
sS'external_loop.thisRepN'
p1072
I0
sS'external_loop.thisIndex'
p1073
g703
sa(dp1074
g690
I1
sg15
g55
sg691
I38
sg23
g27
sS'Sessions.thisN'
p1075
I38
sS'external_loop.thisN'
p1076
I1
sg29
g30
sg18
F0.59966588020324707
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p1077
g24
(g52
S'&\x00\x00\x00'
tRp1078
sg31
V
sS'external_loop.thisTrialN'
p1079
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1080
I38
sS'Sessions.thisRepN'
p1081
I0
sg40
g700
sS'external_loop.thisRepN'
p1082
I0
sS'external_loop.thisIndex'
p1083
g703
sa(dp1084
g690
I2
sg15
g55
sg691
I39
sg23
g27
sS'Sessions.thisN'
p1085
I39
sS'external_loop.thisN'
p1086
I1
sg29
g30
sg18
F0.7806708812713623
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1087
g24
(g52
S"'\x00\x00\x00"
tRp1088
sg31
V
sS'external_loop.thisTrialN'
p1089
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1090
I39
sS'Sessions.thisRepN'
p1091
I0
sg40
g700
sS'external_loop.thisRepN'
p1092
I0
sS'external_loop.thisIndex'
p1093
g703
sa(dp1094
g690
I1
sg15
g55
sg691
I40
sg23
g27
sS'Sessions.thisN'
p1095
I40
sS'external_loop.thisN'
p1096
I1
sg29
g30
sg18
F0.61701488494873047
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p1097
g24
(g52
S'(\x00\x00\x00'
tRp1098
sg31
V
sS'external_loop.thisTrialN'
p1099
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1100
I40
sS'Sessions.thisRepN'
p1101
I0
sg40
g700
sS'external_loop.thisRepN'
p1102
I0
sS'external_loop.thisIndex'
p1103
g703
sa(dp1104
g690
I1
sg15
g47
sg691
I41
sg23
g27
sS'Sessions.thisN'
p1105
I41
sS'external_loop.thisN'
p1106
I1
sg29
g30
sg18
F0.61576604843139648
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1107
g24
(g52
S')\x00\x00\x00'
tRp1108
sg31
V
sS'external_loop.thisTrialN'
p1109
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1110
I41
sS'Sessions.thisRepN'
p1111
I0
sg40
g700
sS'external_loop.thisRepN'
p1112
I0
sS'external_loop.thisIndex'
p1113
g703
sa(dp1114
g690
I2
sg15
g55
sg691
I42
sg23
g27
sS'Sessions.thisN'
p1115
I42
sS'external_loop.thisN'
p1116
I1
sg29
g30
sg18
F0.9319159984588623
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1117
g24
(g52
S'*\x00\x00\x00'
tRp1118
sg31
V
sS'external_loop.thisTrialN'
p1119
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p1120
I42
sS'Sessions.thisRepN'
p1121
I0
sg40
g700
sS'external_loop.thisRepN'
p1122
I0
sS'external_loop.thisIndex'
p1123
g703
sa(dp1124
g690
I2
sg15
g55
sg691
I43
sg23
g27
sS'Sessions.thisN'
p1125
I43
sS'external_loop.thisN'
p1126
I1
sg29
g30
sg18
F0.58439993858337402
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1127
g24
(g52
S'+\x00\x00\x00'
tRp1128
sg31
V
sS'external_loop.thisTrialN'
p1129
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1130
I43
sS'Sessions.thisRepN'
p1131
I0
sg40
g700
sS'external_loop.thisRepN'
p1132
I0
sS'external_loop.thisIndex'
p1133
g703
sa(dp1134
g690
I1
sg15
g55
sg691
I44
sg23
g27
sS'Sessions.thisN'
p1135
I44
sS'external_loop.thisN'
p1136
I1
sg29
g30
sg18
F0.73250603675842285
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p1137
g24
(g52
S',\x00\x00\x00'
tRp1138
sg31
V
sS'external_loop.thisTrialN'
p1139
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p1140
I44
sS'Sessions.thisRepN'
p1141
I0
sg40
g700
sS'external_loop.thisRepN'
p1142
I0
sS'external_loop.thisIndex'
p1143
g703
sa(dp1144
g690
I1
sg15
g47
sg691
I45
sg23
g27
sS'Sessions.thisN'
p1145
I45
sS'external_loop.thisN'
p1146
I1
sg29
g30
sg18
F0.59967398643493652
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1147
g24
(g52
S'-\x00\x00\x00'
tRp1148
sg31
V
sS'external_loop.thisTrialN'
p1149
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1150
I45
sS'Sessions.thisRepN'
p1151
I0
sg40
g700
sS'external_loop.thisRepN'
p1152
I0
sS'external_loop.thisIndex'
p1153
g703
sa(dp1154
g690
I1
sg15
g47
sg691
I46
sg23
g27
sS'Sessions.thisN'
p1155
I46
sS'external_loop.thisN'
p1156
I1
sg29
g30
sg18
F0.73803400993347168
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1157
g24
(g52
S'.\x00\x00\x00'
tRp1158
sg31
V
sS'external_loop.thisTrialN'
p1159
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p1160
I46
sS'Sessions.thisRepN'
p1161
I0
sg40
g700
sS'external_loop.thisRepN'
p1162
I0
sS'external_loop.thisIndex'
p1163
g703
sa(dp1164
g690
I2
sg15
g47
sg691
I47
sg23
g27
sS'Sessions.thisN'
p1165
I47
sS'external_loop.thisN'
p1166
I1
sg29
g30
sg18
F0.59531092643737793
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p1167
g24
(g52
S'/\x00\x00\x00'
tRp1168
sg31
V
sS'external_loop.thisTrialN'
p1169
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1170
I47
sS'Sessions.thisRepN'
p1171
I0
sg40
g700
sS'external_loop.thisRepN'
p1172
I0
sS'external_loop.thisIndex'
p1173
g703
sa(dp1174
g690
I2
sg15
g55
sg691
I48
sg23
g27
sS'Sessions.thisN'
p1175
I48
sS'external_loop.thisN'
p1176
I1
sg29
g30
sg18
F0.58150911331176758
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1177
g24
(g52
S'0\x00\x00\x00'
tRp1178
sg31
V
sS'external_loop.thisTrialN'
p1179
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p1180
I48
sS'Sessions.thisRepN'
p1181
I0
sg40
g700
sS'external_loop.thisRepN'
p1182
I0
sS'external_loop.thisIndex'
p1183
g703
sa(dp1184
g690
I2
sg15
g55
sg691
I49
sg23
g27
sS'Sessions.thisN'
p1185
I49
sS'external_loop.thisN'
p1186
I1
sg29
g30
sg18
F0.59901881217956543
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1187
g24
(g52
S'1\x00\x00\x00'
tRp1188
sg31
V
sS'external_loop.thisTrialN'
p1189
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1190
I49
sS'Sessions.thisRepN'
p1191
I0
sg40
g700
sS'external_loop.thisRepN'
p1192
I0
sS'external_loop.thisIndex'
p1193
g703
sa(dp1194
g690
I2
sg15
g55
sg691
I50
sg23
g27
sS'Sessions.thisN'
p1195
I50
sS'external_loop.thisN'
p1196
I1
sg29
g30
sg18
F0.45054817199707031
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1197
g24
(g52
S'2\x00\x00\x00'
tRp1198
sg31
V
sS'external_loop.thisTrialN'
p1199
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p1200
I50
sS'Sessions.thisRepN'
p1201
I0
sg40
g700
sS'external_loop.thisRepN'
p1202
I0
sS'external_loop.thisIndex'
p1203
g703
sa(dp1204
g690
I1
sg15
g55
sg691
I51
sg23
g27
sS'Sessions.thisN'
p1205
I51
sS'external_loop.thisN'
p1206
I1
sg29
g30
sg18
F0.91315007209777832
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p1207
g24
(g52
S'3\x00\x00\x00'
tRp1208
sg31
V
sS'external_loop.thisTrialN'
p1209
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p1210
I51
sS'Sessions.thisRepN'
p1211
I0
sg40
g700
sS'external_loop.thisRepN'
p1212
I0
sS'external_loop.thisIndex'
p1213
g703
sa(dp1214
g690
I2
sg15
g55
sg691
I52
sg23
g27
sS'Sessions.thisN'
p1215
I52
sS'external_loop.thisN'
p1216
I1
sg29
g30
sg18
F0.61700201034545898
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1217
g24
(g52
S'4\x00\x00\x00'
tRp1218
sg31
V
sS'external_loop.thisTrialN'
p1219
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p1220
I52
sS'Sessions.thisRepN'
p1221
I0
sg40
g700
sS'external_loop.thisRepN'
p1222
I0
sS'external_loop.thisIndex'
p1223
g703
sa(dp1224
g690
I1
sg15
g47
sg691
I53
sg23
g27
sS'Sessions.thisN'
p1225
I53
sS'external_loop.thisN'
p1226
I1
sg29
g30
sg18
F0.76674294471740723
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1227
g24
(g52
S'5\x00\x00\x00'
tRp1228
sg31
V
sS'external_loop.thisTrialN'
p1229
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1230
I53
sS'Sessions.thisRepN'
p1231
I0
sg40
g700
sS'external_loop.thisRepN'
p1232
I0
sS'external_loop.thisIndex'
p1233
g703
sa(dp1234
g690
I2
sg15
g55
sg691
I54
sg23
g27
sS'Sessions.thisN'
p1235
I54
sS'external_loop.thisN'
p1236
I1
sg29
g30
sg18
F1.0662369728088379
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1237
g24
(g52
S'6\x00\x00\x00'
tRp1238
sg31
V
sS'external_loop.thisTrialN'
p1239
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1240
I54
sS'Sessions.thisRepN'
p1241
I0
sg40
g700
sS'external_loop.thisRepN'
p1242
I0
sS'external_loop.thisIndex'
p1243
g703
sa(dp1244
g690
I2
sg15
g55
sg691
I55
sg23
g27
sS'Sessions.thisN'
p1245
I55
sS'external_loop.thisN'
p1246
I1
sg29
g30
sg18
F0.45992803573608398
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1247
g24
(g52
S'7\x00\x00\x00'
tRp1248
sg31
V
sS'external_loop.thisTrialN'
p1249
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p1250
I55
sS'Sessions.thisRepN'
p1251
I0
sg40
g700
sS'external_loop.thisRepN'
p1252
I0
sS'external_loop.thisIndex'
p1253
g703
sa(dp1254
g690
I2
sg15
g55
sg691
I56
sg23
g27
sS'Sessions.thisN'
p1255
I56
sS'external_loop.thisN'
p1256
I1
sg29
g30
sg18
F0.45357990264892578
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1257
g24
(g52
S'8\x00\x00\x00'
tRp1258
sg31
V
sS'external_loop.thisTrialN'
p1259
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p1260
I56
sS'Sessions.thisRepN'
p1261
I0
sg40
g700
sS'external_loop.thisRepN'
p1262
I0
sS'external_loop.thisIndex'
p1263
g703
sa(dp1264
g690
I1
sg15
g55
sg691
I57
sg23
g27
sS'Sessions.thisN'
p1265
I57
sS'external_loop.thisN'
p1266
I1
sg29
g30
sg18
F0.45743513107299805
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p1267
g24
(g52
S'9\x00\x00\x00'
tRp1268
sg31
V
sS'external_loop.thisTrialN'
p1269
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p1270
I57
sS'Sessions.thisRepN'
p1271
I0
sg40
g700
sS'external_loop.thisRepN'
p1272
I0
sS'external_loop.thisIndex'
p1273
g703
sa(dp1274
g690
I2
sg15
g55
sg691
I58
sg23
g27
sS'Sessions.thisN'
p1275
I58
sS'external_loop.thisN'
p1276
I1
sg29
g30
sg18
F0.92500209808349609
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1277
g24
(g52
S':\x00\x00\x00'
tRp1278
sg31
V
sS'external_loop.thisTrialN'
p1279
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p1280
I58
sS'Sessions.thisRepN'
p1281
I0
sg40
g700
sS'external_loop.thisRepN'
p1282
I0
sS'external_loop.thisIndex'
p1283
g703
sa(dp1284
g690
I2
sg15
g55
sg691
I59
sg23
g27
sS'Sessions.thisN'
p1285
I59
sS'external_loop.thisN'
p1286
I1
sg29
g30
sg18
F0.44954013824462891
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1287
g24
(g52
S';\x00\x00\x00'
tRp1288
sg31
V
sS'external_loop.thisTrialN'
p1289
I1
sg14
g47
sg697
I1
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1290
I59
sS'Sessions.thisRepN'
p1291
I0
sg40
g700
sS'external_loop.thisRepN'
p1292
I0
sS'external_loop.thisIndex'
p1293
g703
sa(dp1294
g690
I1
sg15
g47
sg691
I60
sg23
g27
sS'Sessions.thisN'
p1295
I60
sS'external_loop.thisN'
p1296
I1
sg29
g30
sg18
F0.46042299270629883
sg21
g22
sg16
g50
sS'Sessions.thisIndex'
p1297
g24
(g52
S'<\x00\x00\x00'
tRp1298
sg31
V
sS'external_loop.thisTrialN'
p1299
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1300
I60
sS'Sessions.thisRepN'
p1301
I0
sg40
g700
sS'external_loop.thisRepN'
p1302
I0
sS'external_loop.thisIndex'
p1303
g703
sa(dp1304
g690
I1
sg15
g55
sg691
I61
sg23
g27
sS'Sessions.thisN'
p1305
I61
sS'external_loop.thisN'
p1306
I1
sg29
g30
sg18
F0.7685539722442627
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p1307
g24
(g52
S'=\x00\x00\x00'
tRp1308
sg31
V
sS'external_loop.thisTrialN'
p1309
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'p'
sS'Sessions.thisTrialN'
p1310
I61
sS'Sessions.thisRepN'
p1311
I0
sg40
g700
sS'external_loop.thisRepN'
p1312
I0
sS'external_loop.thisIndex'
p1313
g703
sa(dp1314
g690
I1
sg15
g55
sg691
I62
sg23
g27
sS'Sessions.thisN'
p1315
I62
sS'external_loop.thisN'
p1316
I1
sg29
g30
sg18
F0.45020794868469238
sg21
g22
sg16
g76
sS'Sessions.thisIndex'
p1317
g24
(g52
S'>\x00\x00\x00'
tRp1318
sg31
V
sS'external_loop.thisTrialN'
p1319
I1
sg14
g55
sg697
I2
sg28
g11
sg17
S'q'
sS'Sessions.thisTrialN'
p1320
I62
sS'Sessions.thisRepN'
p1321
I0
sg40
g700
sS'external_loop.thisRepN'
p1322
I0
sS'external_loop.thisIndex'
p1323
g703
sa(dp1324
g29
g30
sg31
V
sS'external_loop.thisTrialN'
p1325
I1
sg23
g27
sS'external_loop.thisN'
p1326
I1
sg28
g11
sg21
g22
sg40
g700
sS'external_loop.thisRepN'
p1327
I0
sS'external_loop.thisIndex'
p1328
g703
sasS'loops'
p1329
(lp1330
g1
(cpsychopy.data
TrialHandler
p1331
g3
NtRp1332
(dp1333
S'origin'
p1334
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2013 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import gui, logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000aimport psychopy\u000aimport cPickle, string, sys, platform, os, time, copy, csv\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom contrib.quest import *    #used for QuestHandler\u000aimport inspect #so that Handlers can find the script that called them\u000aimport codecs, locale\u000aimport weakref\u000aimport re\u000a\u000atry:\u000a    import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept:\u000a    haveOpenpyxl=False\u000a\u000a_experiments=weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW') # will match all bad var name chars\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a    def __init__(self,\u000a                name='',\u000a                version='',\u000a                extraInfo=None,\u000a                runtimeInfo=None,\u000a                originPath=None,\u000a                savePickle=True,\u000a                saveWideText=True,\u000a                dataFileName=''):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFilename : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless .abort()\u000a                had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a        """\u000a        self.loops=[]\u000a        self.loopsUnfinished=[]\u000a        self.name=name\u000a        self.version=version\u000a        self.runtimeInfo=runtimeInfo\u000a        if extraInfo==None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo=extraInfo\u000a        self.originPath=originPath\u000a        self.savePickle=savePickle\u000a        self.saveWideText=saveWideText\u000a        self.dataFileName=dataFileName\u000a        self.thisEntry = {}\u000a        self.entries=[]#chronological list of entries\u000a        self._paramNamesSoFar=[]\u000a        self.dataNames=[]#names of all the data (eg. resp.keys)\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName parameter. No data will be saved in the event of a crash')\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            logging.debug('Saving data for %s ExperimentHandler' %self.name)\u000a            if self.savePickle==True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText==True:\u000a                self.saveAsWideText(self.dataFileName+'.csv', delim=',')\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler` or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        #keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names=copy.deepcopy(self._paramNamesSoFar)\u000a        #get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a    def _getExtraInfo(self):\u000a        """\u000a        Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names=[]\u000a            vals=[]\u000a        else:\u000a            names=self.extraInfo.keys()\u000a            vals= self.extraInfo.values()\u000a        return names, vals\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial of a particular loop.\u000a        Does not return data inputs from the subject, only info relating to the trial\u000a        execution.\u000a        """\u000a        names=[]\u000a        vals=[]\u000a        name = loop.name\u000a        #standard attributes\u000a        for attr in ['thisRepN', 'thisTrialN', 'thisN','thisIndex', 'stepSizeCurrent']:\u000a            if hasattr(loop, attr):\u000a                if attr=='stepSizeCurrent':\u000a                    attrName=name+'.stepSize'\u000a                else:\u000a                    attrName = name+'.'+attr\u000a                #append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop,attr))\u000a        #method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial,'items'):#is a TrialList object or a simple dict\u000a                for attr,val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a            elif trial==[]:#we haven't had 1st trial yet? Not actually sure why this occasionally happens (JWP)\u000a                pass\u000a            else:\u000a                names.append(name+'.thisTrial')\u000a                vals.append(trial)\u000a        #single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name+'.intensity')\u000a            if len(loop.intensities)>0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            #add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            #end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        self.thisEntry[name]=value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further\u000a        addData() calls correspond to the next trial.\u000a        """\u000a        this=self.thisEntry\u000a        #fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name]=vals[n]\u000a        #add the extraInfo dict to the data\u000a        if type(self.extraInfo)==dict:\u000a            this.update(self.extraInfo)#NB update() really means mergeFrom()\u000a        self.entries.append(this)\u000a        #then create new empty entry for n\u000a        self.thisEntry = {}\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=False):\u000a        """Saves a long, wide-format text file, with one line representing the attributes and data\u000a        for a single trial. Suitable for analysis in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of an existing file. Otherwise, if the file exists\u000a        already it will be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row, which can be handy if you want to append data\u000a        to an existing file of the same format.\u000a        """\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if os.path.exists(fileName) and writeFormat == 'w':\u000a            logging.warning('Data file, %s, will be overwritten' %fileName)\u000a\u000a        if fileName[-4:] in ['.csv', '.CSV']:\u000a            delim=','\u000a        else:\u000a            delim='\u005ct'\u000a\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.csv', '.CSV','.dlm','.DLM', '.tsv','.TSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        names.extend(self._getExtraInfo()[0]) #names from the extraInfo dictionary\u000a        #write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        #write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    if ',' in unicode(entry[name]):\u000a                        f.write(u'"%s"%s' %(entry[name],delim))\u000a                    else:\u000a                        f.write(u'%s%s' %(entry[name],delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        f.close()\u000a        self.saveWideText=False\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        #no need to save again\u000a        self.savePickle=False\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data (even in the event of a crash if possible).\u000a        So if you quit your script early you may want to tell the Handler not to save out the data files for this run.\u000a        This is the method that allows you to do that.\u000a        """\u000a        self.savePickle=False\u000a        self.saveWideText=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                raise AttributeError, ('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a\u000aclass _BaseTrialHandler(object):\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        #need to use a weakref to avoid creating a circular reference that\u000a        #prevents effective object deletion\u000a        expId=id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to, if any.\u000a        Returns None if not attached\u000a        """\u000a        if self._exp==None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        #remove ourself from the list of unfinished loops in the experiment\u000a        exp=self.getExp()\u000a        if exp!=None:\u000a            exp.loopEnded(self)\u000a        #and halt the loop\u000a        raise StopIteration\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of the handler (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessesary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('.saveAsPickle() called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a    def saveAsText(self,fileName,\u000a                   stimOut=[],\u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a         :Parameters:\u000a\u000a            fileName:\u000a                will have .dlm appended (so you can double-click it to\u000a                open in excel) and can include path info.\u000a\u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings\u000a\u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=[],\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #set default delimiter if none given\u000a        if delim==None:\u000a            if fileName[-4:] in ['.csv','.CSV']:\u000a                delim=','\u000a            else:\u000a                delim='\u005ct'\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv', '.CSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        #loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                if delim in unicode(entry):#surround in quotes to prevent effect of delimiter\u000a                    f.write(u'"%s"' %unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN<(len(line)-1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")#add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved data to %s' %f.name)\u000a    def printAsText(self, stimOut=[],\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=[],\u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided\u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler\u000a                and give here the names of strings specifying entries in that dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction\u000a                times across the trials assuming that `rt` values have been stored.\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=[],\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line==None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry in [None]:\u000a                    entry=''\u000a                try:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = float(entry)#if it can conver to a number (from numpy) then do it\u000a                except:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = unicode(entry)#else treat as unicode\u000a\u000a        ew.save(filename = fileName)\u000a\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            logging.warning("""DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this data file\u000a        and returns both the path to that script and it's contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used otherwise\u000a        the calling script is the originPath (fine from a standard python script).\u000a        """\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a                logging.debug("Using %s as origin file" %originPath)\u000a            except:\u000a                logging.debug("Failed to find origin file using inspect.getouterframes")\u000a                return '',''\u000a        if os.path.isfile(originPath):#do we NOW have a path?\u000a            origin = codecs.open(originPath,"r", encoding = "utf-8").read()\u000a        else:\u000a            origin=None\u000a        return originPath, origin\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom). Calls\u000a    will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the TrialHandler object that\u000a    saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name=''):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries specifying conditions\u000a                This can be imported from an excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order they appear in the list.\u000a                'random' will result in a shuffle of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom' fully randomises the\u000a                trials across repeats as well, which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g. ['corr','rt','resp']\u000a                If not provided then these will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes the experiment and\u000a                subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script/experiment file path\u000a                The psydat file format will store a copy of the experiment if possible. If no file path\u000a                is provided here then the TrialHandler will still store a copy of the script where it was\u000a                created\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that created the handler\u000a\u000a        """\u000a        self.name=name\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(trialList):\u000a            if type(entry)==dict:\u000a                trialList[n]=TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0        #records which repetition or pass we are on\u000a        self.thisTrialN = -1    #records which trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0        #the index of the current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a\u000a        #print data first, then all others\u000a        try: data=self.data\u000a        except: data=None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a\u000a        strRepres+=')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations (for non-adaptive methods).\u000a        This is called automatically when the TrialHandler is initialised so doesn't\u000a        need an explicit call from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy, and\u000a        specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed=self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps,1) # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(randomFlat, (len(indices), self.nReps))\u000a        logging.exp('Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s' %\u000a                (self.method, len(indices), self.nReps, str(self.seed) )  )\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a\u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a\u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1#number of trial this pass\u000a        self.thisN+=1 #number of trial in total\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a\u000a        if self.finished==True:\u000a            self._terminate()\u000a\u000a        #fetch the trial info\u000a        if self.method in ['random','sequential','fullRandom']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a            self.data.add('order',self.thisN)\u000a        logging.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without advancing\u000a        the trials. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative offsets:\u000a        if n>self.nRemaining or self.thisN+n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex=seqs[self.thisN+n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously. Useful\u000a        for comparisons in n-back tasks. Returns 'None' if trying to access a trial\u000a        prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0: n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def _createOutputArray(self,stimOut,dataOut,delim=None,\u000a                          matrixOnly=False):\u000a        """\u000a        Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if stimOut==[] and len(self.trialList) and hasattr(self.trialList[0],'keys'):\u000a            stimOut=self.trialList[0].keys()\u000a            #these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines=[]\u000a        #parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut=dataOut)\u000a        if not matrixOnly:\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum': heading ='n'\u000a                elif heading=='order_raw': heading ='order'\u000a                thisLine.append(heading)\u000a\u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): #is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    #for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion=strVersion.replace('None','')\u000a                elif tmpData in [None,'None']:\u000a                    strVersion=''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion=='()':\u000a                    strVersion="--"# 'no data' in masked array should show as "--"\u000a                #handle list of values (e.g. rt_raw )\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    strVersion=strVersion[1:-1]#skip first and last chars\u000a                #handle lists of lists (e.g. raw of multiple key presses)\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    tup = eval(strVersion) #convert back to a tuple\u000a                    for entry in tup:\u000a                        #contents of each entry is a list or tuple so keep in quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            lines.append(['extraInfo'])#give a single line of space and then a heading\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key,value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header line and adds the stimOut columns\u000a        """\u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])    #will store data that has been analyzed\u000a        if type(dataOut)==str: dataOut=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list: dataOut = list(dataOut)\u000a\u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        #treat these separately later\u000a        allDataTypes.remove('ran')\u000a        #ready to go trhough standard data types\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut=='n':\u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if dataType=='all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew: dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew: dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew\u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a\u000a        #do the various analyses, keeping track of fails (e.g. mean of a string)\u000a        dataOutInvalid=[]\u000a        #add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        if 'order_raw' in dataOut:#move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. his should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal*=0 #prevent a divide-by-zero error\u000a                        else:\u000a                            thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError, 'You can only use analyses from numpy'\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:\u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a\u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid: dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a\u000a    def saveAsWideText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                  ):\u000a        """\u000a        Write a text file with the session, stimulus, and data values from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and various other analysis programs, means that some\u000a        information must be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each entry in there occurs in every row.\u000a        In builder, this will include any entries in the 'Experiment info' field of the 'Experiment settings' dialog.\u000a        In Coder, this information can be set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith', 'DOB':1970 Nov 16, 'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists.\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if appendFile:\u000a            writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.tsv', '.TSV', '.txt', '.TXT', '.csv', '.CSV']:\u000a            f = codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',': f = codecs.open(fileName+'.csv', writeFormat, encoding="utf-8")\u000a            else: f=codecs.open(fileName+'.txt',writeFormat, encoding = "utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of repetitions:\u000a\u000a        repsPerType={}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                #find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                #determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex]=0\u000a                else:\u000a                    repsPerType[trialTypeIndex]+=1\u000a                repThisType=repsPerType[trialTypeIndex]#what repeat are we on for this trial type?\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g. subject ID, date, etc) repeated every line if it exists:\u000a                if (self.extraInfo != None):\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # now collect the value from each trial of the variables named in the header:\u000a                for parameterName in header:\u000a                    # the header includes both trial and data variables, so need to check before accessing:\u000a                    if self.trialList[trialTypeIndex] and parameterName in self.trialList[trialTypeIndex]:\u000a                        nextEntry[parameterName] = self.trialList[trialTypeIndex][parameterName]\u000a                    elif parameterName in self.data:\u000a                        nextEntry[parameterName] = self.data[parameterName][trialTypeIndex][repThisType]\u000a                    else: # allow a null value if this parameter wasn't explicitly stored on this trial:\u000a                        nextEntry[parameterName] = ''\u000a\u000a                #store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0,"TrialNumber")\u000a        if (self.extraInfo != None):\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        if not matrixOnly:\u000a        # write the header row:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + parameterName + delim\u000a            f.write(nextLine[:-1] + '\u005cn') # remove the final orphaned tab character\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + unicode(trial[parameterName]) + delim\u000a            nextLine = nextLine[:-1] # remove the final orphaned tab character\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' %f.name)\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp()!=None:#update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). Please use `importConditions` for identical functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000adef importConditions(fileName, returnFieldNames=False):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler` `trialTypes` or to\u000a    :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a        - .csv:  import as a comma-separated-value file (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files. Sorry no support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all names are\u000a        OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            raise ImportError, 'Conditions file %s: Missing parameter name(s); empty cell(s) in the first row?' % fileName\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK: #tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError, 'Conditions file %s: %s%s"%s"' %(fileName, msg, os.linesep*2, name)\u000a\u000a    if fileName in ['None','none',None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        raise ImportError, 'Conditions file not found: %s' %os.path.abspath(fileName)\u000a\u000a    if fileName.endswith('.csv'):\u000a        #use csv import library to fetch the fieldNames\u000a        f = open(fileName, 'rU')#the U converts line endings to os.linesep (not unicode!)\u000a        trialsArr = numpy.recfromcsv(f)\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        f.close()\u000a        #convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial ={}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                if type(val)==numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    #if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        #exec('val=%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU') # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except:\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0] # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                thisTrial[fieldName] = row[fieldN] # type is correct, being .pkl\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for loading excel format files, but it was not found.'\u000a        try:\u000a            wb = load_workbook(filename = fileName)\u000a        except: # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        ws = wb.worksheets[0]\u000a        nCols = ws.get_highest_column()\u000a        nRows = ws.get_highest_row()\u000a\u000a        #get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        #loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):#skip header first row\u000a            thisTrial={}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                #if it looks like a list, convert it\u000a                if type(val) in [unicode, str] and (\u000a                        val.startswith('[') and val.endswith(']') or\u000a                        val.startswith('(') and val.endswith(')') ):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                 (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList,fieldNames)\u000a    else:\u000a        return trialList\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a\u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"],\u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``demo_trialHandler.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name=''):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in\u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a        """\u000a\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a\u000a            """\u000a        self.name=name\u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a\u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True\u000a\u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either\u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.otherData={} #a dict of lists where each should have the same length as the main data\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def __iter__(self):\u000a        return self\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity!=None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        #increment the counter of correct scores\u000a        if result==1:\u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additonal data to the handler, to be tracked alongside the result\u000a        data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData: #init the list\u000a            if self.thisTrialN>0:\u000a                self.otherData[dataName]=[None]*(self.thisTrialN-1) #might have run trals already\u000a            else:\u000a                self.otherData[dataName]=[]\u000a        #then add current value\u000a        self.otherData[dataName].append(value)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous. Please use one of\u000a        these instead:\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a\u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially\u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                self._intensityDec()\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                self._intensityInc()\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a\u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            #make it harder\u000a            self._intensityDec()\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a\u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!\u000a            #make it easier\u000a            self._intensityInc()\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a\u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a\u000a\u000a        #add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a        #test if we're done\u000a        if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a            len(self.intensities)>=self.nTrials:\u000a                self.finished=True\u000a        #new step size if necessary\u000a        if reversal and self._variableStep and self.finished==False:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                #we've gone beyond the list of step sizes so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        if self.finished==False:\u000a            #check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key])<self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv','.CSV']:\u000a            f= file(fileName,'w')\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a\u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', delim)\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', delim)\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', delim)\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', delim)\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved data to %s' %f.name)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a\u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a\u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        logging.info('saved data to %s' %fileName)\u000a\u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1:\u000a            logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' %f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addData(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name=''):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold..\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a\u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels\u000a                into decibels or log units and will move along the psychometric function with these values.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a\u000a        """\u000a\u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method,\u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal, name=name)\u000a\u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a\u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp=None\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  #remove the one that had been auto-generated\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError, "length of intensities and results input must be the same"\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addData(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a\u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        else:\u000a            scaled_intensity = intensity\u000a        return scaled_intensity\u000a\u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        else:\u000a            intensity = scaled_intensity\u000a        return intensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode()[0])\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest,\u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50, originPath=None, name=''):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or\u000a        QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above handlers)\u000a        a `label` to tag the staircase and a `startValSd` (only for QUEST\u000a        staircases). Any parameters not specified in the conditions file\u000a        will revert to the default for that individual handler.\u000a\u000a        If you need to custom the behaviour further you may want to look at the\u000a        recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than\u000a                that (so you can't have 3 repeats of the same staircase in a row\u000a                unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importTrialTypes`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't\u000a                also met its minimal reversals. See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                #do something with thisIntensity and thisOri\u000a\u000a                stairs.addData(correctIncorrect)#this is ESSENTIAL\u000a\u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a\u000a        """\u000a        self.name=name\u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a\u000a        #fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            logging.error('conditions parameter to MultiStairHandler should be a list, not a %s' %type(self.conditions))\u000a            return\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            logging.error('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest']:\u000a            if 'startVal' not in params:\u000a                logging.error('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params:\u000a                logging.error('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type=='quest':\u000a                logging.error("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            logging.error("MultiStairHandler `stairType` should be 'simple' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials,\u000a                'nUp':1, 'nDown':3, 'extraInfo':None,\u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type=='quest':\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None,\u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01,\u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None,\u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a\u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter\u000a                if paramName in condition.keys(): val=condition[paramName]\u000a                else: val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals,\u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown,\u000a                    extraInfo=extraInfo,\u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type=='quest':\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'],\u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval,\u000a                    method=method, stepType=stepType, beta=beta, delta=delta,\u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo,\u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        #if staircase.next() not called, staircaseHandler would not save the first intensity,\u000a        #Error: miss align intensities and responses\u000a        try:\u000a            self._nextIntensity =self.currentStaircase.next()#gets updated by self.addData()\u000a        except:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a            if len(self.runningStaircases)==0: #If finished,set finished flag \u000a                self.finished=True\u000a        #return value\u000a        if not self.finished:\u000a            #inform experiment of the condition (but not intensity, that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" %(self.name, key), value)\u000a                exp.addData(self.name+'.thisIndex', self.conditions.index(stair.condition))\u000a                exp.addData(self.name+'.thisRepN', stair.thisTrialN+1)\u000a                exp.addData(self.name+'.thisN', self.totalTrials)\u000a                exp.addData(self.name+'.direction', stair.currentDirection)\u000a                exp.addData(self.name+'.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name+'.stepType', stair.stepType)\u000a                exp.addData(self.name+'.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed byt he user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method=='random': numpy.random.shuffle(self.thisPassRemaining)\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.totalTrials+=1\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the curent trial that will not be used to control the\u000a        staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding the response\u000a        (0 or 1) or some other data concerning the trial so there is now a pair\u000a        of explicit methods:\u000a            addResponse(corr,intensity) #some data that alters the next trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't control staircase\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in [str, unicode]:\u000a            raise TypeError, "MultiStairHandler.addData should only receive corr/incorr. Use .addOtherData('datName',val)"\u000a    def saveAsPickle(self, fileName):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a        """\u000a        if self.totalTrials<1:\u000a            logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' %f.name)\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN==0: append=appendFile\u000a            else: append=True\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(fileName=fileName, sheetName=label,\u000a                matrixOnly=matrixOnly, appendFile=append)\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        if self.totalTrials<1:\u000a            logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(fileName=thisFileName, delim=delim,\u000a                matrixOnly=matrixOnly)\u000a    def printAsText(self,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs=len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN<(nStairs-1): thisMatrixOnly=True #never print info for first files\u000a            else: thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" %label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                matrixOnly=thisMatrixOnly)\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape: self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape: shape = self.dataShape\u000a        if not isinstance(names,basestring):\u000a            #recursively call this function until we have a string\u000a            for thisName in names: self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position==None:\u000a            #'ran' is always the first thing to update\u000a            if thisType=='ran':\u000a                repN = sum(self['ran'][self.trials.thisIndex])\u000a            else:\u000a                repN = sum(self['ran'][self.trials.thisIndex])-1#because it has already been updated\u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            logging.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    def __init__(self, fnName, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        raise "FitFunction is now fully DEPRECATED: use FitLogistic, FitWeibull etc instead"\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        #get some useful variables to help choose starting fit vals\u000a        #self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        #self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(self._eval, self.xx, self.yy)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params = self.params\u000a        global _chance\u000a        _chance=self.expectedMin\u000a        #_eval is a static method - must be done this way because the curve_fit\u000a        #function doesn't want to have any `self` object as first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params=self.params #so the user can set params for this particular inv\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)"""\u000a    #static mathods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy =  _chance + (1.0-_chance)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-_chance))) **(1.0/beta)\u000a        return xx\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    #static mathods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50<=0: c50=0.001\u000a        if n<=0: n=0.001\u000a        if rMax<=0: n=0.001\u000a        if rMin<=0: n=0.001\u000a        yy = rMin + (rMax-rMin)*(xx**n/(xx**n+c50**n))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy-rMin)/(rMax-rMin) #remove baseline and scale\u000a        #do we need to shift while fitting?\u000a        yScaled[yScaled<0]=0\u000a        xx = (yScaled*(c50)**n/(1-yScaled))**(1/n)\u000a        return xx\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    #static mathods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-_chance)/(yy-_chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*(special.erf(xx*xScale - xShift)/2.0+0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = (erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params\u000a    (a list with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is more in\u000a    with the parameters for the Weibull fit, for instance, it is less in keeping\u000a    with standard expectations of normal (Gaussian distributions) so in version\u000a    1.74.00 the parameters became the [centre,sd] of the normal distribution.\u000a\u000a    """\u000a    #static mathods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1-_chance)*(special.erf((xx-xShift)/sd)/2.0+0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        #xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erfinv() goes from -1:1\u000a        xx = xShift+sd*special.erfinv(( (yy-_chance)/(1-_chance) - 0.5 )*2)\u000a        return xx\u000a\u000a########################## End psychopy.data classes ##########################\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a\u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure\u000a\u000a    usage::\u000a\u000a        [intensity, meanCorrect, n] = functionFromStaircase(intensities, responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique' (where each bin is made from ALL data for exactly one intensity value)\u000a\u000a            intensity\u000a                is the center of an intensity bin\u000a\u000a            meanCorrect\u000a                is mean % correct in that bin\u000a\u000a            n\u000a                is number of responses contributing to that mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp=[]; binnedInten=[]; nPoints = []\u000a    if bins=='unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a\u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    depending on locale, can have unicode chars in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_dec = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        now_dec = time.strftime("%Y_%m_%d_%H%M", time.localtime())  # '2011_03_16_1307'\u000a\u000a    return now_dec\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in [str, unicode, numpy.string_, numpy.unicode_]:\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            raise AttributeError, "name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name))\u000a        else:\u000a            raise AttributeError, "name %s (type %s) could not be converted to a string" % (name, type(name))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a\u000a
p1335
sS'thisTrial'
p1336
(lp1337
sS'_exp'
p1338
I211564400
sg10
S'external_loop'
p1339
sg6
S'/Applications/PsychoPy2.app/Contents/Resources/lib/python2.7/psychopy/data.py'
p1340
sS'thisRepN'
p1341
I1
sS'nTotal'
p1342
I2
sg19
g20
sS'data'
p1343
g1
(cpsychopy.data
DataHandler
p1344
c__builtin__
dict
p1345
(dp1346
S'ran'
p1347
cnumpy.ma.core
_mareconstruct
p1348
(cnumpy.ma.core
MaskedArray
p1349
cnumpy
ndarray
p1350
(I0
tp1351
S'b'
tRp1352
(I1
(I2
I1
tg25
(S'f4'
I0
I1
tRp1353
(I3
S'<'
NNNI-1
I-1
I0
tbI00
S'\x00\x00\x80?\x00\x00\x80?'
S'\x00\x00'
NtbsS'order'
p1354
g1348
(g1349
g1350
g1351
S'b'
tRp1355
(I1
(I2
I1
tg1353
I00
S'\x00\x00\x00\x00\x00\x00\x80?'
S'\x00\x00'
NtbstRp1356
(dp1357
S'isNumeric'
p1358
(dp1359
g1347
I01
sg1354
I01
ssS'trials'
p1360
g1332
sS'dataTypes'
p1361
(lp1362
g1347
ag1354
asS'dataShape'
p1363
(lp1364
I2
aI1
asbsS'thisN'
p1365
I2
sS'sequenceIndices'
p1366
cnumpy.core.multiarray
_reconstruct
p1367
(g1350
(I0
tS'b'
tRp1368
(I1
(I2
I1
tg52
I00
S'\x00\x00\x00\x00\x01\x00\x00\x00'
tbsS'finished'
p1369
I01
sS'nReps'
p1370
I1
sS'nRemaining'
p1371
I-1
sS'trialList'
p1372
(lp1373
g1
(cpsychopy.data
TrialType
p1374
g1345
(dp1375
g40
g58
stRp1376
ag1
(g1374
g1345
(dp1377
g40
g700
stRp1378
asS'seed'
p1379
NsS'thisIndex'
p1380
g703
sS'thisTrialN'
p1381
I0
sS'method'
p1382
S'sequential'
p1383
sS'_warnUseOfNext'
p1384
I01
sbag1
(g1331
g3
NtRp1385
(dp1386
g1334
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2013 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import gui, logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000aimport psychopy\u000aimport cPickle, string, sys, platform, os, time, copy, csv\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom contrib.quest import *    #used for QuestHandler\u000aimport inspect #so that Handlers can find the script that called them\u000aimport codecs, locale\u000aimport weakref\u000aimport re\u000a\u000atry:\u000a    import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept:\u000a    haveOpenpyxl=False\u000a\u000a_experiments=weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW') # will match all bad var name chars\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a    def __init__(self,\u000a                name='',\u000a                version='',\u000a                extraInfo=None,\u000a                runtimeInfo=None,\u000a                originPath=None,\u000a                savePickle=True,\u000a                saveWideText=True,\u000a                dataFileName=''):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFilename : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless .abort()\u000a                had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a        """\u000a        self.loops=[]\u000a        self.loopsUnfinished=[]\u000a        self.name=name\u000a        self.version=version\u000a        self.runtimeInfo=runtimeInfo\u000a        if extraInfo==None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo=extraInfo\u000a        self.originPath=originPath\u000a        self.savePickle=savePickle\u000a        self.saveWideText=saveWideText\u000a        self.dataFileName=dataFileName\u000a        self.thisEntry = {}\u000a        self.entries=[]#chronological list of entries\u000a        self._paramNamesSoFar=[]\u000a        self.dataNames=[]#names of all the data (eg. resp.keys)\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName parameter. No data will be saved in the event of a crash')\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            logging.debug('Saving data for %s ExperimentHandler' %self.name)\u000a            if self.savePickle==True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText==True:\u000a                self.saveAsWideText(self.dataFileName+'.csv', delim=',')\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler` or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        #keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names=copy.deepcopy(self._paramNamesSoFar)\u000a        #get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a    def _getExtraInfo(self):\u000a        """\u000a        Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names=[]\u000a            vals=[]\u000a        else:\u000a            names=self.extraInfo.keys()\u000a            vals= self.extraInfo.values()\u000a        return names, vals\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial of a particular loop.\u000a        Does not return data inputs from the subject, only info relating to the trial\u000a        execution.\u000a        """\u000a        names=[]\u000a        vals=[]\u000a        name = loop.name\u000a        #standard attributes\u000a        for attr in ['thisRepN', 'thisTrialN', 'thisN','thisIndex', 'stepSizeCurrent']:\u000a            if hasattr(loop, attr):\u000a                if attr=='stepSizeCurrent':\u000a                    attrName=name+'.stepSize'\u000a                else:\u000a                    attrName = name+'.'+attr\u000a                #append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop,attr))\u000a        #method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial,'items'):#is a TrialList object or a simple dict\u000a                for attr,val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a            elif trial==[]:#we haven't had 1st trial yet? Not actually sure why this occasionally happens (JWP)\u000a                pass\u000a            else:\u000a                names.append(name+'.thisTrial')\u000a                vals.append(trial)\u000a        #single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name+'.intensity')\u000a            if len(loop.intensities)>0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            #add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            #end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        self.thisEntry[name]=value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further\u000a        addData() calls correspond to the next trial.\u000a        """\u000a        this=self.thisEntry\u000a        #fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name]=vals[n]\u000a        #add the extraInfo dict to the data\u000a        if type(self.extraInfo)==dict:\u000a            this.update(self.extraInfo)#NB update() really means mergeFrom()\u000a        self.entries.append(this)\u000a        #then create new empty entry for n\u000a        self.thisEntry = {}\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=False):\u000a        """Saves a long, wide-format text file, with one line representing the attributes and data\u000a        for a single trial. Suitable for analysis in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of an existing file. Otherwise, if the file exists\u000a        already it will be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row, which can be handy if you want to append data\u000a        to an existing file of the same format.\u000a        """\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if os.path.exists(fileName) and writeFormat == 'w':\u000a            logging.warning('Data file, %s, will be overwritten' %fileName)\u000a\u000a        if fileName[-4:] in ['.csv', '.CSV']:\u000a            delim=','\u000a        else:\u000a            delim='\u005ct'\u000a\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.csv', '.CSV','.dlm','.DLM', '.tsv','.TSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        names.extend(self._getExtraInfo()[0]) #names from the extraInfo dictionary\u000a        #write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        #write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    if ',' in unicode(entry[name]):\u000a                        f.write(u'"%s"%s' %(entry[name],delim))\u000a                    else:\u000a                        f.write(u'%s%s' %(entry[name],delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        f.close()\u000a        self.saveWideText=False\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        #no need to save again\u000a        self.savePickle=False\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data (even in the event of a crash if possible).\u000a        So if you quit your script early you may want to tell the Handler not to save out the data files for this run.\u000a        This is the method that allows you to do that.\u000a        """\u000a        self.savePickle=False\u000a        self.saveWideText=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                raise AttributeError, ('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a\u000aclass _BaseTrialHandler(object):\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        #need to use a weakref to avoid creating a circular reference that\u000a        #prevents effective object deletion\u000a        expId=id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to, if any.\u000a        Returns None if not attached\u000a        """\u000a        if self._exp==None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        #remove ourself from the list of unfinished loops in the experiment\u000a        exp=self.getExp()\u000a        if exp!=None:\u000a            exp.loopEnded(self)\u000a        #and halt the loop\u000a        raise StopIteration\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of the handler (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessesary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('.saveAsPickle() called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a    def saveAsText(self,fileName,\u000a                   stimOut=[],\u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a         :Parameters:\u000a\u000a            fileName:\u000a                will have .dlm appended (so you can double-click it to\u000a                open in excel) and can include path info.\u000a\u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings\u000a\u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=[],\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #set default delimiter if none given\u000a        if delim==None:\u000a            if fileName[-4:] in ['.csv','.CSV']:\u000a                delim=','\u000a            else:\u000a                delim='\u005ct'\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv', '.CSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        #loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                if delim in unicode(entry):#surround in quotes to prevent effect of delimiter\u000a                    f.write(u'"%s"' %unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN<(len(line)-1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")#add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved data to %s' %f.name)\u000a    def printAsText(self, stimOut=[],\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=[],\u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided\u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler\u000a                and give here the names of strings specifying entries in that dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction\u000a                times across the trials assuming that `rt` values have been stored.\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=[],\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line==None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry in [None]:\u000a                    entry=''\u000a                try:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = float(entry)#if it can conver to a number (from numpy) then do it\u000a                except:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = unicode(entry)#else treat as unicode\u000a\u000a        ew.save(filename = fileName)\u000a\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            logging.warning("""DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this data file\u000a        and returns both the path to that script and it's contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used otherwise\u000a        the calling script is the originPath (fine from a standard python script).\u000a        """\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a                logging.debug("Using %s as origin file" %originPath)\u000a            except:\u000a                logging.debug("Failed to find origin file using inspect.getouterframes")\u000a                return '',''\u000a        if os.path.isfile(originPath):#do we NOW have a path?\u000a            origin = codecs.open(originPath,"r", encoding = "utf-8").read()\u000a        else:\u000a            origin=None\u000a        return originPath, origin\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom). Calls\u000a    will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the TrialHandler object that\u000a    saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name=''):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries specifying conditions\u000a                This can be imported from an excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order they appear in the list.\u000a                'random' will result in a shuffle of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom' fully randomises the\u000a                trials across repeats as well, which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g. ['corr','rt','resp']\u000a                If not provided then these will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes the experiment and\u000a                subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script/experiment file path\u000a                The psydat file format will store a copy of the experiment if possible. If no file path\u000a                is provided here then the TrialHandler will still store a copy of the script where it was\u000a                created\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that created the handler\u000a\u000a        """\u000a        self.name=name\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(trialList):\u000a            if type(entry)==dict:\u000a                trialList[n]=TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0        #records which repetition or pass we are on\u000a        self.thisTrialN = -1    #records which trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0        #the index of the current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a\u000a        #print data first, then all others\u000a        try: data=self.data\u000a        except: data=None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a\u000a        strRepres+=')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations (for non-adaptive methods).\u000a        This is called automatically when the TrialHandler is initialised so doesn't\u000a        need an explicit call from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy, and\u000a        specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed=self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps,1) # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(randomFlat, (len(indices), self.nReps))\u000a        logging.exp('Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s' %\u000a                (self.method, len(indices), self.nReps, str(self.seed) )  )\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a\u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a\u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1#number of trial this pass\u000a        self.thisN+=1 #number of trial in total\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a\u000a        if self.finished==True:\u000a            self._terminate()\u000a\u000a        #fetch the trial info\u000a        if self.method in ['random','sequential','fullRandom']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a            self.data.add('order',self.thisN)\u000a        logging.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without advancing\u000a        the trials. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative offsets:\u000a        if n>self.nRemaining or self.thisN+n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex=seqs[self.thisN+n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously. Useful\u000a        for comparisons in n-back tasks. Returns 'None' if trying to access a trial\u000a        prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0: n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def _createOutputArray(self,stimOut,dataOut,delim=None,\u000a                          matrixOnly=False):\u000a        """\u000a        Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if stimOut==[] and len(self.trialList) and hasattr(self.trialList[0],'keys'):\u000a            stimOut=self.trialList[0].keys()\u000a            #these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines=[]\u000a        #parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut=dataOut)\u000a        if not matrixOnly:\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum': heading ='n'\u000a                elif heading=='order_raw': heading ='order'\u000a                thisLine.append(heading)\u000a\u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): #is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    #for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion=strVersion.replace('None','')\u000a                elif tmpData in [None,'None']:\u000a                    strVersion=''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion=='()':\u000a                    strVersion="--"# 'no data' in masked array should show as "--"\u000a                #handle list of values (e.g. rt_raw )\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    strVersion=strVersion[1:-1]#skip first and last chars\u000a                #handle lists of lists (e.g. raw of multiple key presses)\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    tup = eval(strVersion) #convert back to a tuple\u000a                    for entry in tup:\u000a                        #contents of each entry is a list or tuple so keep in quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            lines.append(['extraInfo'])#give a single line of space and then a heading\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key,value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header line and adds the stimOut columns\u000a        """\u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])    #will store data that has been analyzed\u000a        if type(dataOut)==str: dataOut=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list: dataOut = list(dataOut)\u000a\u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        #treat these separately later\u000a        allDataTypes.remove('ran')\u000a        #ready to go trhough standard data types\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut=='n':\u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if dataType=='all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew: dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew: dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew\u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a\u000a        #do the various analyses, keeping track of fails (e.g. mean of a string)\u000a        dataOutInvalid=[]\u000a        #add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        if 'order_raw' in dataOut:#move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. his should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal*=0 #prevent a divide-by-zero error\u000a                        else:\u000a                            thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError, 'You can only use analyses from numpy'\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:\u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a\u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid: dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a\u000a    def saveAsWideText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                  ):\u000a        """\u000a        Write a text file with the session, stimulus, and data values from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and various other analysis programs, means that some\u000a        information must be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each entry in there occurs in every row.\u000a        In builder, this will include any entries in the 'Experiment info' field of the 'Experiment settings' dialog.\u000a        In Coder, this information can be set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith', 'DOB':1970 Nov 16, 'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists.\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if appendFile:\u000a            writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.tsv', '.TSV', '.txt', '.TXT', '.csv', '.CSV']:\u000a            f = codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',': f = codecs.open(fileName+'.csv', writeFormat, encoding="utf-8")\u000a            else: f=codecs.open(fileName+'.txt',writeFormat, encoding = "utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of repetitions:\u000a\u000a        repsPerType={}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                #find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                #determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex]=0\u000a                else:\u000a                    repsPerType[trialTypeIndex]+=1\u000a                repThisType=repsPerType[trialTypeIndex]#what repeat are we on for this trial type?\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g. subject ID, date, etc) repeated every line if it exists:\u000a                if (self.extraInfo != None):\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # now collect the value from each trial of the variables named in the header:\u000a                for parameterName in header:\u000a                    # the header includes both trial and data variables, so need to check before accessing:\u000a                    if self.trialList[trialTypeIndex] and parameterName in self.trialList[trialTypeIndex]:\u000a                        nextEntry[parameterName] = self.trialList[trialTypeIndex][parameterName]\u000a                    elif parameterName in self.data:\u000a                        nextEntry[parameterName] = self.data[parameterName][trialTypeIndex][repThisType]\u000a                    else: # allow a null value if this parameter wasn't explicitly stored on this trial:\u000a                        nextEntry[parameterName] = ''\u000a\u000a                #store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0,"TrialNumber")\u000a        if (self.extraInfo != None):\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        if not matrixOnly:\u000a        # write the header row:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + parameterName + delim\u000a            f.write(nextLine[:-1] + '\u005cn') # remove the final orphaned tab character\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + unicode(trial[parameterName]) + delim\u000a            nextLine = nextLine[:-1] # remove the final orphaned tab character\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' %f.name)\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp()!=None:#update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). Please use `importConditions` for identical functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000adef importConditions(fileName, returnFieldNames=False):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler` `trialTypes` or to\u000a    :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a        - .csv:  import as a comma-separated-value file (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files. Sorry no support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all names are\u000a        OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            raise ImportError, 'Conditions file %s: Missing parameter name(s); empty cell(s) in the first row?' % fileName\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK: #tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError, 'Conditions file %s: %s%s"%s"' %(fileName, msg, os.linesep*2, name)\u000a\u000a    if fileName in ['None','none',None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        raise ImportError, 'Conditions file not found: %s' %os.path.abspath(fileName)\u000a\u000a    if fileName.endswith('.csv'):\u000a        #use csv import library to fetch the fieldNames\u000a        f = open(fileName, 'rU')#the U converts line endings to os.linesep (not unicode!)\u000a        trialsArr = numpy.recfromcsv(f)\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        f.close()\u000a        #convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial ={}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                if type(val)==numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    #if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        #exec('val=%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU') # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except:\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0] # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                thisTrial[fieldName] = row[fieldN] # type is correct, being .pkl\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for loading excel format files, but it was not found.'\u000a        try:\u000a            wb = load_workbook(filename = fileName)\u000a        except: # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        ws = wb.worksheets[0]\u000a        nCols = ws.get_highest_column()\u000a        nRows = ws.get_highest_row()\u000a\u000a        #get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        #loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):#skip header first row\u000a            thisTrial={}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                #if it looks like a list, convert it\u000a                if type(val) in [unicode, str] and (\u000a                        val.startswith('[') and val.endswith(']') or\u000a                        val.startswith('(') and val.endswith(')') ):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                 (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList,fieldNames)\u000a    else:\u000a        return trialList\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a\u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"],\u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``demo_trialHandler.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name=''):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in\u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a        """\u000a\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a\u000a            """\u000a        self.name=name\u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a\u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True\u000a\u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either\u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.otherData={} #a dict of lists where each should have the same length as the main data\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def __iter__(self):\u000a        return self\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity!=None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        #increment the counter of correct scores\u000a        if result==1:\u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additonal data to the handler, to be tracked alongside the result\u000a        data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData: #init the list\u000a            if self.thisTrialN>0:\u000a                self.otherData[dataName]=[None]*(self.thisTrialN-1) #might have run trals already\u000a            else:\u000a                self.otherData[dataName]=[]\u000a        #then add current value\u000a        self.otherData[dataName].append(value)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous. Please use one of\u000a        these instead:\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a\u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially\u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                self._intensityDec()\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                self._intensityInc()\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a\u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            #make it harder\u000a            self._intensityDec()\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a\u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!\u000a            #make it easier\u000a            self._intensityInc()\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a\u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a\u000a\u000a        #add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a        #test if we're done\u000a        if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a            len(self.intensities)>=self.nTrials:\u000a                self.finished=True\u000a        #new step size if necessary\u000a        if reversal and self._variableStep and self.finished==False:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                #we've gone beyond the list of step sizes so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        if self.finished==False:\u000a            #check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key])<self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv','.CSV']:\u000a            f= file(fileName,'w')\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a\u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', delim)\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', delim)\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', delim)\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', delim)\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved data to %s' %f.name)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a\u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a\u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        logging.info('saved data to %s' %fileName)\u000a\u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1:\u000a            logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' %f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addData(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name=''):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold..\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a\u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels\u000a                into decibels or log units and will move along the psychometric function with these values.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a\u000a        """\u000a\u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method,\u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal, name=name)\u000a\u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a\u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp=None\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  #remove the one that had been auto-generated\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError, "length of intensities and results input must be the same"\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addData(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a\u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        else:\u000a            scaled_intensity = intensity\u000a        return scaled_intensity\u000a\u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        else:\u000a            intensity = scaled_intensity\u000a        return intensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode()[0])\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest,\u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50, originPath=None, name=''):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or\u000a        QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above handlers)\u000a        a `label` to tag the staircase and a `startValSd` (only for QUEST\u000a        staircases). Any parameters not specified in the conditions file\u000a        will revert to the default for that individual handler.\u000a\u000a        If you need to custom the behaviour further you may want to look at the\u000a        recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than\u000a                that (so you can't have 3 repeats of the same staircase in a row\u000a                unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importTrialTypes`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't\u000a                also met its minimal reversals. See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                #do something with thisIntensity and thisOri\u000a\u000a                stairs.addData(correctIncorrect)#this is ESSENTIAL\u000a\u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a\u000a        """\u000a        self.name=name\u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a\u000a        #fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            logging.error('conditions parameter to MultiStairHandler should be a list, not a %s' %type(self.conditions))\u000a            return\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            logging.error('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest']:\u000a            if 'startVal' not in params:\u000a                logging.error('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params:\u000a                logging.error('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type=='quest':\u000a                logging.error("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            logging.error("MultiStairHandler `stairType` should be 'simple' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials,\u000a                'nUp':1, 'nDown':3, 'extraInfo':None,\u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type=='quest':\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None,\u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01,\u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None,\u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a\u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter\u000a                if paramName in condition.keys(): val=condition[paramName]\u000a                else: val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals,\u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown,\u000a                    extraInfo=extraInfo,\u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type=='quest':\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'],\u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval,\u000a                    method=method, stepType=stepType, beta=beta, delta=delta,\u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo,\u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        #if staircase.next() not called, staircaseHandler would not save the first intensity,\u000a        #Error: miss align intensities and responses\u000a        try:\u000a            self._nextIntensity =self.currentStaircase.next()#gets updated by self.addData()\u000a        except:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a            if len(self.runningStaircases)==0: #If finished,set finished flag \u000a                self.finished=True\u000a        #return value\u000a        if not self.finished:\u000a            #inform experiment of the condition (but not intensity, that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" %(self.name, key), value)\u000a                exp.addData(self.name+'.thisIndex', self.conditions.index(stair.condition))\u000a                exp.addData(self.name+'.thisRepN', stair.thisTrialN+1)\u000a                exp.addData(self.name+'.thisN', self.totalTrials)\u000a                exp.addData(self.name+'.direction', stair.currentDirection)\u000a                exp.addData(self.name+'.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name+'.stepType', stair.stepType)\u000a                exp.addData(self.name+'.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed byt he user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method=='random': numpy.random.shuffle(self.thisPassRemaining)\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.totalTrials+=1\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the curent trial that will not be used to control the\u000a        staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding the response\u000a        (0 or 1) or some other data concerning the trial so there is now a pair\u000a        of explicit methods:\u000a            addResponse(corr,intensity) #some data that alters the next trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't control staircase\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in [str, unicode]:\u000a            raise TypeError, "MultiStairHandler.addData should only receive corr/incorr. Use .addOtherData('datName',val)"\u000a    def saveAsPickle(self, fileName):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a        """\u000a        if self.totalTrials<1:\u000a            logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' %f.name)\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN==0: append=appendFile\u000a            else: append=True\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(fileName=fileName, sheetName=label,\u000a                matrixOnly=matrixOnly, appendFile=append)\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        if self.totalTrials<1:\u000a            logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(fileName=thisFileName, delim=delim,\u000a                matrixOnly=matrixOnly)\u000a    def printAsText(self,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs=len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN<(nStairs-1): thisMatrixOnly=True #never print info for first files\u000a            else: thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" %label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                matrixOnly=thisMatrixOnly)\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape: self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape: shape = self.dataShape\u000a        if not isinstance(names,basestring):\u000a            #recursively call this function until we have a string\u000a            for thisName in names: self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position==None:\u000a            #'ran' is always the first thing to update\u000a            if thisType=='ran':\u000a                repN = sum(self['ran'][self.trials.thisIndex])\u000a            else:\u000a                repN = sum(self['ran'][self.trials.thisIndex])-1#because it has already been updated\u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            logging.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    def __init__(self, fnName, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        raise "FitFunction is now fully DEPRECATED: use FitLogistic, FitWeibull etc instead"\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        #get some useful variables to help choose starting fit vals\u000a        #self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        #self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(self._eval, self.xx, self.yy)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params = self.params\u000a        global _chance\u000a        _chance=self.expectedMin\u000a        #_eval is a static method - must be done this way because the curve_fit\u000a        #function doesn't want to have any `self` object as first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params=self.params #so the user can set params for this particular inv\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)"""\u000a    #static mathods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy =  _chance + (1.0-_chance)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-_chance))) **(1.0/beta)\u000a        return xx\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    #static mathods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50<=0: c50=0.001\u000a        if n<=0: n=0.001\u000a        if rMax<=0: n=0.001\u000a        if rMin<=0: n=0.001\u000a        yy = rMin + (rMax-rMin)*(xx**n/(xx**n+c50**n))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy-rMin)/(rMax-rMin) #remove baseline and scale\u000a        #do we need to shift while fitting?\u000a        yScaled[yScaled<0]=0\u000a        xx = (yScaled*(c50)**n/(1-yScaled))**(1/n)\u000a        return xx\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    #static mathods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-_chance)/(yy-_chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*(special.erf(xx*xScale - xShift)/2.0+0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = (erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params\u000a    (a list with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is more in\u000a    with the parameters for the Weibull fit, for instance, it is less in keeping\u000a    with standard expectations of normal (Gaussian distributions) so in version\u000a    1.74.00 the parameters became the [centre,sd] of the normal distribution.\u000a\u000a    """\u000a    #static mathods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1-_chance)*(special.erf((xx-xShift)/sd)/2.0+0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        #xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erfinv() goes from -1:1\u000a        xx = xShift+sd*special.erfinv(( (yy-_chance)/(1-_chance) - 0.5 )*2)\u000a        return xx\u000a\u000a########################## End psychopy.data classes ##########################\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a\u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure\u000a\u000a    usage::\u000a\u000a        [intensity, meanCorrect, n] = functionFromStaircase(intensities, responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique' (where each bin is made from ALL data for exactly one intensity value)\u000a\u000a            intensity\u000a                is the center of an intensity bin\u000a\u000a            meanCorrect\u000a                is mean % correct in that bin\u000a\u000a            n\u000a                is number of responses contributing to that mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp=[]; binnedInten=[]; nPoints = []\u000a    if bins=='unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a\u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    depending on locale, can have unicode chars in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_dec = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        now_dec = time.strftime("%Y_%m_%d_%H%M", time.localtime())  # '2011_03_16_1307'\u000a\u000a    return now_dec\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in [str, unicode, numpy.string_, numpy.unicode_]:\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            raise AttributeError, "name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name))\u000a        else:\u000a            raise AttributeError, "name %s (type %s) could not be converted to a string" % (name, type(name))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a\u000a
p1387
sg1336
(lp1388
sg1338
I211564400
sg10
S'Sessions'
p1389
sg6
g1340
sg1341
I1
sg1342
I63
sg19
g20
sg1343
g1
(g1344
g1345
(dp1390
g17
g1367
(g1350
(I0
tS'b'
tRp1391
(I1
(I63
I1
tg25
(S'O4'
I0
I1
tRp1392
(I3
S'|'
NNNI-1
I-1
I63
tbI00
(lp1393
S'q'
aNaS'p'
aS'p'
aS'q'
aS'p'
aS'p'
aS'p'
aS'q'
aS'q'
aS'q'
aS'q'
aS'p'
aS'q'
aS'q'
aS'p'
aS'p'
aS'p'
aS'p'
aS'p'
aS'p'
aS'p'
aS'p'
aS'p'
aS'p'
aS'p'
aS'p'
aS'q'
aS'p'
aS'p'
aS'q'
aS'p'
aNaS'q'
aS'p'
aS'p'
aS'p'
aS'q'
aS'p'
aNaS'q'
aS'p'
aS'q'
aS'q'
aS'p'
aNaS'q'
aS'q'
aS'q'
aS'q'
aS'p'
aS'q'
aS'p'
aS'q'
aS'q'
aS'p'
aS'p'
aS'q'
aS'p'
aS'p'
aS'p'
aS'q'
aS'p'
atbsg16
g1367
(g1350
(I0
tS'b'
tRp1394
(I1
(I63
I1
tg1392
I00
(lp1395
g50
ag65
ag76
ag76
ag50
ag76
ag50
ag50
ag76
ag50
ag50
ag50
ag76
ag50
ag76
ag76
ag50
ag76
ag76
ag76
ag76
ag50
ag76
ag50
ag76
ag50
ag50
ag50
ag76
ag50
ag76
ag76
ag65
ag50
ag76
ag76
ag76
ag76
ag50
ag65
ag76
ag76
ag50
ag50
ag50
ag65
ag50
ag76
ag50
ag50
ag50
ag76
ag50
ag76
ag76
ag50
ag50
ag76
ag50
ag50
ag76
ag76
ag50
atbsg15
g1367
(g1350
(I0
tS'b'
tRp1396
(I1
(I63
I1
tg1392
I00
(lp1397
g47
ag65
ag47
ag55
ag55
ag55
ag55
ag47
ag55
ag47
ag47
ag47
ag47
ag47
ag55
ag47
ag47
ag47
ag55
ag55
ag55
ag47
ag47
ag55
ag55
ag55
ag55
ag55
ag55
ag55
ag47
ag47
ag65
ag55
ag47
ag55
ag55
ag47
ag55
ag65
ag47
ag47
ag47
ag47
ag55
ag65
ag55
ag55
ag47
ag47
ag47
ag47
ag47
ag47
ag55
ag47
ag47
ag47
ag47
ag47
ag47
ag47
ag55
atbsg1347
g1348
(g1349
g1350
g1351
S'b'
tRp1398
(I1
(I63
I1
tg1353
I00
S'\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg18
g1348
(g1349
g1350
g1351
S'b'
tRp1399
(I1
(I63
I1
tg1353
I00
S"8O\xcc>\x00\x00\x00\x00\\\x04\x1a?\xd83\xe4>\xb8\xf1\xde>\xf0\xef\xe5>dV\x17?\x00k\xe6>\x00.\xe0>\xe0\x85\x15?\x08\x89\xe4>\x80\xd3\xe2>\xb8\xee\x1d?\xa0\x9cd?\x10\xacf?d\xde>?T\xeef?\xb8\xd8`?Xg\xe5>\xb0@\xe5>\x10'\xe8>|`\x17?Pw\xe7>\xcc\xff\x17?h\xb2;? -f? \x04<?x\n\xe9>\x88t\xe0>\xe0D\xe5>8\xb6\xe6>\x18\x85\x19?\x00\x00\x00\x00\x0c\x11\x17?h\x1b\xcf?p\xe3\xdd>\xc8wa?tQ\x1c?\x98\xfe\xe4>\x00\x00\x00\x00D\xc2??\x9e\xd4\x85?PND?\xe0\xb6\xe7>\xd8j\xe6>\x00\x00\x00\x00\xd0]\xf6?\x84Og?F\xee\xab?\xf4\x8a\x17?\xfcd\x18?P\xba\x1b>\x10\xfck?\\Y\x1a?@:\x15>*U\x88?\xa8\xfa\xe5>,L??h(\x19?\xdc\xa9h?\xbc\x0b@?\xe8\x1c\x9b>P\xa3\xe1>"
S'\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg14
g1367
(g1350
(I0
tS'b'
tRp1400
(I1
(I63
I1
tg1392
I00
(lp1401
g55
ag47
ag47
ag55
ag47
ag55
ag47
ag55
ag55
ag55
ag55
ag55
ag47
ag55
ag55
ag47
ag55
ag47
ag55
ag55
ag55
ag55
ag47
ag47
ag55
ag47
ag47
ag47
ag55
ag47
ag47
ag47
ag47
ag47
ag47
ag55
ag55
ag47
ag47
ag55
ag47
ag47
ag55
ag55
ag47
ag47
ag47
ag55
ag55
ag55
ag55
ag47
ag55
ag47
ag55
ag55
ag55
ag47
ag55
ag55
ag47
ag47
ag47
atbsg1354
g1348
(g1349
g1350
g1351
S'b'
tRp1402
(I1
(I63
I1
tg1353
I00
S'\x00\x00\x00\x00\x00\x00\x80?\x00\x00\x00@\x00\x00@@\x00\x00\x80@\x00\x00\xa0@\x00\x00\xc0@\x00\x00\xe0@\x00\x00\x00A\x00\x00\x10A\x00\x00 A\x00\x000A\x00\x00@A\x00\x00PA\x00\x00`A\x00\x00pA\x00\x00\x80A\x00\x00\x88A\x00\x00\x90A\x00\x00\x98A\x00\x00\xa0A\x00\x00\xa8A\x00\x00\xb0A\x00\x00\xb8A\x00\x00\xc0A\x00\x00\xc8A\x00\x00\xd0A\x00\x00\xd8A\x00\x00\xe0A\x00\x00\xe8A\x00\x00\xf0A\x00\x00\xf8A\x00\x00\x00B\x00\x00\x04B\x00\x00\x08B\x00\x00\x0cB\x00\x00\x10B\x00\x00\x14B\x00\x00\x18B\x00\x00\x1cB\x00\x00 B\x00\x00$B\x00\x00(B\x00\x00,B\x00\x000B\x00\x004B\x00\x008B\x00\x00<B\x00\x00@B\x00\x00DB\x00\x00HB\x00\x00LB\x00\x00PB\x00\x00TB\x00\x00XB\x00\x00\\B\x00\x00`B\x00\x00dB\x00\x00hB\x00\x00lB\x00\x00pB\x00\x00tB\x00\x00xB'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
NtbstRp1403
(dp1404
g1358
(dp1405
g16
I00
sg15
I00
sg1347
I01
sg14
I00
sg17
I00
sg18
I01
sg1354
I01
ssg1360
g1385
sg1361
(lp1406
g1347
ag1354
ag14
ag15
ag16
ag17
ag18
asg1363
(lp1407
I63
aI1
asbsg1365
I63
sg1366
g1367
(g1350
(I0
tS'b'
tRp1408
(I1
(I63
I1
tg52
I00
S'\x00\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\x03\x00\x00\x00\x04\x00\x00\x00\x05\x00\x00\x00\x06\x00\x00\x00\x07\x00\x00\x00\x08\x00\x00\x00\t\x00\x00\x00\n\x00\x00\x00\x0b\x00\x00\x00\x0c\x00\x00\x00\r\x00\x00\x00\x0e\x00\x00\x00\x0f\x00\x00\x00\x10\x00\x00\x00\x11\x00\x00\x00\x12\x00\x00\x00\x13\x00\x00\x00\x14\x00\x00\x00\x15\x00\x00\x00\x16\x00\x00\x00\x17\x00\x00\x00\x18\x00\x00\x00\x19\x00\x00\x00\x1a\x00\x00\x00\x1b\x00\x00\x00\x1c\x00\x00\x00\x1d\x00\x00\x00\x1e\x00\x00\x00\x1f\x00\x00\x00 \x00\x00\x00!\x00\x00\x00"\x00\x00\x00#\x00\x00\x00$\x00\x00\x00%\x00\x00\x00&\x00\x00\x00\'\x00\x00\x00(\x00\x00\x00)\x00\x00\x00*\x00\x00\x00+\x00\x00\x00,\x00\x00\x00-\x00\x00\x00.\x00\x00\x00/\x00\x00\x000\x00\x00\x001\x00\x00\x002\x00\x00\x003\x00\x00\x004\x00\x00\x005\x00\x00\x006\x00\x00\x007\x00\x00\x008\x00\x00\x009\x00\x00\x00:\x00\x00\x00;\x00\x00\x00<\x00\x00\x00=\x00\x00\x00>\x00\x00\x00'
tbsg1369
I01
sg1370
I1
sg1371
I-1
sg1372
(lp1409
g1
(g1374
g1345
(dp1410
g41
I1
sg42
I0
sg43
I2
stRp1411
ag1
(g1374
g1345
(dp1412
g41
I2
sg42
I1
sg43
I1
stRp1413
ag1
(g1374
g1345
(dp1414
g41
I2
sg42
I2
sg43
I1
stRp1415
ag1
(g1374
g1345
(dp1416
g41
I1
sg42
I3
sg43
I2
stRp1417
ag1
(g1374
g1345
(dp1418
g41
I2
sg42
I4
sg43
I1
stRp1419
ag1
(g1374
g1345
(dp1420
g41
I1
sg42
I5
sg43
I2
stRp1421
ag1
(g1374
g1345
(dp1422
g41
I2
sg42
I6
sg43
I1
stRp1423
ag1
(g1374
g1345
(dp1424
g41
I1
sg42
I7
sg43
I2
stRp1425
ag1
(g1374
g1345
(dp1426
g41
I1
sg42
I8
sg43
I2
stRp1427
ag1
(g1374
g1345
(dp1428
g41
I1
sg42
I9
sg43
I2
stRp1429
ag1
(g1374
g1345
(dp1430
g41
I1
sg42
I10
sg43
I2
stRp1431
ag1
(g1374
g1345
(dp1432
g41
I1
sg42
I11
sg43
I2
stRp1433
ag1
(g1374
g1345
(dp1434
g41
I2
sg42
I12
sg43
I1
stRp1435
ag1
(g1374
g1345
(dp1436
g41
I1
sg42
I13
sg43
I2
stRp1437
ag1
(g1374
g1345
(dp1438
g41
I1
sg42
I14
sg43
I2
stRp1439
ag1
(g1374
g1345
(dp1440
g41
I2
sg42
I15
sg43
I1
stRp1441
ag1
(g1374
g1345
(dp1442
g41
I1
sg42
I16
sg43
I2
stRp1443
ag1
(g1374
g1345
(dp1444
g41
I2
sg42
I17
sg43
I1
stRp1445
ag1
(g1374
g1345
(dp1446
g41
I1
sg42
I18
sg43
I2
stRp1447
ag1
(g1374
g1345
(dp1448
g41
I1
sg42
I19
sg43
I2
stRp1449
ag1
(g1374
g1345
(dp1450
g41
I1
sg42
I20
sg43
I2
stRp1451
ag1
(g1374
g1345
(dp1452
g41
I1
sg42
I21
sg43
I2
stRp1453
ag1
(g1374
g1345
(dp1454
g41
I2
sg42
I22
sg43
I1
stRp1455
ag1
(g1374
g1345
(dp1456
g41
I2
sg42
I23
sg43
I1
stRp1457
ag1
(g1374
g1345
(dp1458
g41
I1
sg42
I24
sg43
I2
stRp1459
ag1
(g1374
g1345
(dp1460
g41
I2
sg42
I25
sg43
I1
stRp1461
ag1
(g1374
g1345
(dp1462
g41
I2
sg42
I26
sg43
I1
stRp1463
ag1
(g1374
g1345
(dp1464
g41
I2
sg42
I27
sg43
I1
stRp1465
ag1
(g1374
g1345
(dp1466
g41
I1
sg42
I28
sg43
I2
stRp1467
ag1
(g1374
g1345
(dp1468
g41
I2
sg42
I29
sg43
I1
stRp1469
ag1
(g1374
g1345
(dp1470
g41
I2
sg42
I30
sg43
I1
stRp1471
ag1
(g1374
g1345
(dp1472
g41
I2
sg42
I31
sg43
I1
stRp1473
ag1
(g1374
g1345
(dp1474
g41
I2
sg42
I32
sg43
I1
stRp1475
ag1
(g1374
g1345
(dp1476
g41
I2
sg42
I33
sg43
I1
stRp1477
ag1
(g1374
g1345
(dp1478
g41
I2
sg42
I34
sg43
I1
stRp1479
ag1
(g1374
g1345
(dp1480
g41
I1
sg42
I35
sg43
I2
stRp1481
ag1
(g1374
g1345
(dp1482
g41
I1
sg42
I36
sg43
I2
stRp1483
ag1
(g1374
g1345
(dp1484
g41
I2
sg42
I37
sg43
I1
stRp1485
ag1
(g1374
g1345
(dp1486
g41
I2
sg42
I38
sg43
I1
stRp1487
ag1
(g1374
g1345
(dp1488
g41
I1
sg42
I39
sg43
I2
stRp1489
ag1
(g1374
g1345
(dp1490
g41
I2
sg42
I40
sg43
I1
stRp1491
ag1
(g1374
g1345
(dp1492
g41
I2
sg42
I41
sg43
I1
stRp1493
ag1
(g1374
g1345
(dp1494
g41
I1
sg42
I42
sg43
I2
stRp1495
ag1
(g1374
g1345
(dp1496
g41
I1
sg42
I43
sg43
I2
stRp1497
ag1
(g1374
g1345
(dp1498
g41
I2
sg42
I44
sg43
I1
stRp1499
ag1
(g1374
g1345
(dp1500
g41
I2
sg42
I45
sg43
I1
stRp1501
ag1
(g1374
g1345
(dp1502
g41
I2
sg42
I46
sg43
I1
stRp1503
ag1
(g1374
g1345
(dp1504
g41
I1
sg42
I47
sg43
I2
stRp1505
ag1
(g1374
g1345
(dp1506
g41
I1
sg42
I48
sg43
I2
stRp1507
ag1
(g1374
g1345
(dp1508
g41
I1
sg42
I49
sg43
I2
stRp1509
ag1
(g1374
g1345
(dp1510
g41
I1
sg42
I50
sg43
I2
stRp1511
ag1
(g1374
g1345
(dp1512
g41
I2
sg42
I51
sg43
I1
stRp1513
ag1
(g1374
g1345
(dp1514
g41
I1
sg42
I52
sg43
I2
stRp1515
ag1
(g1374
g1345
(dp1516
g41
I2
sg42
I53
sg43
I1
stRp1517
ag1
(g1374
g1345
(dp1518
g41
I1
sg42
I54
sg43
I2
stRp1519
ag1
(g1374
g1345
(dp1520
g41
I1
sg42
I55
sg43
I2
stRp1521
ag1
(g1374
g1345
(dp1522
g41
I1
sg42
I56
sg43
I2
stRp1523
ag1
(g1374
g1345
(dp1524
g41
I2
sg42
I57
sg43
I1
stRp1525
ag1
(g1374
g1345
(dp1526
g41
I1
sg42
I58
sg43
I2
stRp1527
ag1
(g1374
g1345
(dp1528
g41
I1
sg42
I59
sg43
I2
stRp1529
ag1
(g1374
g1345
(dp1530
g41
I2
sg42
I60
sg43
I1
stRp1531
ag1
(g1374
g1345
(dp1532
g41
I2
sg42
I61
sg43
I1
stRp1533
ag1
(g1374
g1345
(dp1534
g41
I2
sg42
I62
sg43
I1
stRp1535
asg1379
Nsg1380
g678
sg1381
I0
sg1382
g1383
sg1384
I01
sbag1
(g1331
g3
NtRp1536
(dp1537
g1334
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2013 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import gui, logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000aimport psychopy\u000aimport cPickle, string, sys, platform, os, time, copy, csv\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom contrib.quest import *    #used for QuestHandler\u000aimport inspect #so that Handlers can find the script that called them\u000aimport codecs, locale\u000aimport weakref\u000aimport re\u000a\u000atry:\u000a    import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept:\u000a    haveOpenpyxl=False\u000a\u000a_experiments=weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW') # will match all bad var name chars\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a    def __init__(self,\u000a                name='',\u000a                version='',\u000a                extraInfo=None,\u000a                runtimeInfo=None,\u000a                originPath=None,\u000a                savePickle=True,\u000a                saveWideText=True,\u000a                dataFileName=''):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFilename : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless .abort()\u000a                had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a        """\u000a        self.loops=[]\u000a        self.loopsUnfinished=[]\u000a        self.name=name\u000a        self.version=version\u000a        self.runtimeInfo=runtimeInfo\u000a        if extraInfo==None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo=extraInfo\u000a        self.originPath=originPath\u000a        self.savePickle=savePickle\u000a        self.saveWideText=saveWideText\u000a        self.dataFileName=dataFileName\u000a        self.thisEntry = {}\u000a        self.entries=[]#chronological list of entries\u000a        self._paramNamesSoFar=[]\u000a        self.dataNames=[]#names of all the data (eg. resp.keys)\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName parameter. No data will be saved in the event of a crash')\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            logging.debug('Saving data for %s ExperimentHandler' %self.name)\u000a            if self.savePickle==True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText==True:\u000a                self.saveAsWideText(self.dataFileName+'.csv', delim=',')\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler` or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        #keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names=copy.deepcopy(self._paramNamesSoFar)\u000a        #get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a    def _getExtraInfo(self):\u000a        """\u000a        Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names=[]\u000a            vals=[]\u000a        else:\u000a            names=self.extraInfo.keys()\u000a            vals= self.extraInfo.values()\u000a        return names, vals\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial of a particular loop.\u000a        Does not return data inputs from the subject, only info relating to the trial\u000a        execution.\u000a        """\u000a        names=[]\u000a        vals=[]\u000a        name = loop.name\u000a        #standard attributes\u000a        for attr in ['thisRepN', 'thisTrialN', 'thisN','thisIndex', 'stepSizeCurrent']:\u000a            if hasattr(loop, attr):\u000a                if attr=='stepSizeCurrent':\u000a                    attrName=name+'.stepSize'\u000a                else:\u000a                    attrName = name+'.'+attr\u000a                #append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop,attr))\u000a        #method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial,'items'):#is a TrialList object or a simple dict\u000a                for attr,val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a            elif trial==[]:#we haven't had 1st trial yet? Not actually sure why this occasionally happens (JWP)\u000a                pass\u000a            else:\u000a                names.append(name+'.thisTrial')\u000a                vals.append(trial)\u000a        #single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name+'.intensity')\u000a            if len(loop.intensities)>0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            #add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            #end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        self.thisEntry[name]=value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further\u000a        addData() calls correspond to the next trial.\u000a        """\u000a        this=self.thisEntry\u000a        #fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name]=vals[n]\u000a        #add the extraInfo dict to the data\u000a        if type(self.extraInfo)==dict:\u000a            this.update(self.extraInfo)#NB update() really means mergeFrom()\u000a        self.entries.append(this)\u000a        #then create new empty entry for n\u000a        self.thisEntry = {}\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=False):\u000a        """Saves a long, wide-format text file, with one line representing the attributes and data\u000a        for a single trial. Suitable for analysis in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of an existing file. Otherwise, if the file exists\u000a        already it will be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row, which can be handy if you want to append data\u000a        to an existing file of the same format.\u000a        """\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if os.path.exists(fileName) and writeFormat == 'w':\u000a            logging.warning('Data file, %s, will be overwritten' %fileName)\u000a\u000a        if fileName[-4:] in ['.csv', '.CSV']:\u000a            delim=','\u000a        else:\u000a            delim='\u005ct'\u000a\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.csv', '.CSV','.dlm','.DLM', '.tsv','.TSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        names.extend(self._getExtraInfo()[0]) #names from the extraInfo dictionary\u000a        #write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        #write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    if ',' in unicode(entry[name]):\u000a                        f.write(u'"%s"%s' %(entry[name],delim))\u000a                    else:\u000a                        f.write(u'%s%s' %(entry[name],delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        f.close()\u000a        self.saveWideText=False\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        #no need to save again\u000a        self.savePickle=False\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data (even in the event of a crash if possible).\u000a        So if you quit your script early you may want to tell the Handler not to save out the data files for this run.\u000a        This is the method that allows you to do that.\u000a        """\u000a        self.savePickle=False\u000a        self.saveWideText=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                raise AttributeError, ('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a\u000aclass _BaseTrialHandler(object):\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        #need to use a weakref to avoid creating a circular reference that\u000a        #prevents effective object deletion\u000a        expId=id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to, if any.\u000a        Returns None if not attached\u000a        """\u000a        if self._exp==None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        #remove ourself from the list of unfinished loops in the experiment\u000a        exp=self.getExp()\u000a        if exp!=None:\u000a            exp.loopEnded(self)\u000a        #and halt the loop\u000a        raise StopIteration\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of the handler (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessesary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('.saveAsPickle() called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a    def saveAsText(self,fileName,\u000a                   stimOut=[],\u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a         :Parameters:\u000a\u000a            fileName:\u000a                will have .dlm appended (so you can double-click it to\u000a                open in excel) and can include path info.\u000a\u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings\u000a\u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=[],\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #set default delimiter if none given\u000a        if delim==None:\u000a            if fileName[-4:] in ['.csv','.CSV']:\u000a                delim=','\u000a            else:\u000a                delim='\u005ct'\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv', '.CSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        #loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                if delim in unicode(entry):#surround in quotes to prevent effect of delimiter\u000a                    f.write(u'"%s"' %unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN<(len(line)-1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")#add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved data to %s' %f.name)\u000a    def printAsText(self, stimOut=[],\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=[],\u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided\u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler\u000a                and give here the names of strings specifying entries in that dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction\u000a                times across the trials assuming that `rt` values have been stored.\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=[],\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line==None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry in [None]:\u000a                    entry=''\u000a                try:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = float(entry)#if it can conver to a number (from numpy) then do it\u000a                except:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = unicode(entry)#else treat as unicode\u000a\u000a        ew.save(filename = fileName)\u000a\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            logging.warning("""DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this data file\u000a        and returns both the path to that script and it's contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used otherwise\u000a        the calling script is the originPath (fine from a standard python script).\u000a        """\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a                logging.debug("Using %s as origin file" %originPath)\u000a            except:\u000a                logging.debug("Failed to find origin file using inspect.getouterframes")\u000a                return '',''\u000a        if os.path.isfile(originPath):#do we NOW have a path?\u000a            origin = codecs.open(originPath,"r", encoding = "utf-8").read()\u000a        else:\u000a            origin=None\u000a        return originPath, origin\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom). Calls\u000a    will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the TrialHandler object that\u000a    saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name=''):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries specifying conditions\u000a                This can be imported from an excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order they appear in the list.\u000a                'random' will result in a shuffle of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom' fully randomises the\u000a                trials across repeats as well, which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g. ['corr','rt','resp']\u000a                If not provided then these will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes the experiment and\u000a                subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script/experiment file path\u000a                The psydat file format will store a copy of the experiment if possible. If no file path\u000a                is provided here then the TrialHandler will still store a copy of the script where it was\u000a                created\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that created the handler\u000a\u000a        """\u000a        self.name=name\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(trialList):\u000a            if type(entry)==dict:\u000a                trialList[n]=TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0        #records which repetition or pass we are on\u000a        self.thisTrialN = -1    #records which trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0        #the index of the current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a\u000a        #print data first, then all others\u000a        try: data=self.data\u000a        except: data=None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a\u000a        strRepres+=')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations (for non-adaptive methods).\u000a        This is called automatically when the TrialHandler is initialised so doesn't\u000a        need an explicit call from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy, and\u000a        specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed=self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps,1) # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(randomFlat, (len(indices), self.nReps))\u000a        logging.exp('Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s' %\u000a                (self.method, len(indices), self.nReps, str(self.seed) )  )\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a\u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a\u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1#number of trial this pass\u000a        self.thisN+=1 #number of trial in total\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a\u000a        if self.finished==True:\u000a            self._terminate()\u000a\u000a        #fetch the trial info\u000a        if self.method in ['random','sequential','fullRandom']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a            self.data.add('order',self.thisN)\u000a        logging.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without advancing\u000a        the trials. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative offsets:\u000a        if n>self.nRemaining or self.thisN+n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex=seqs[self.thisN+n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously. Useful\u000a        for comparisons in n-back tasks. Returns 'None' if trying to access a trial\u000a        prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0: n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def _createOutputArray(self,stimOut,dataOut,delim=None,\u000a                          matrixOnly=False):\u000a        """\u000a        Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if stimOut==[] and len(self.trialList) and hasattr(self.trialList[0],'keys'):\u000a            stimOut=self.trialList[0].keys()\u000a            #these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines=[]\u000a        #parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut=dataOut)\u000a        if not matrixOnly:\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum': heading ='n'\u000a                elif heading=='order_raw': heading ='order'\u000a                thisLine.append(heading)\u000a\u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): #is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    #for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion=strVersion.replace('None','')\u000a                elif tmpData in [None,'None']:\u000a                    strVersion=''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion=='()':\u000a                    strVersion="--"# 'no data' in masked array should show as "--"\u000a                #handle list of values (e.g. rt_raw )\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    strVersion=strVersion[1:-1]#skip first and last chars\u000a                #handle lists of lists (e.g. raw of multiple key presses)\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    tup = eval(strVersion) #convert back to a tuple\u000a                    for entry in tup:\u000a                        #contents of each entry is a list or tuple so keep in quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            lines.append(['extraInfo'])#give a single line of space and then a heading\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key,value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header line and adds the stimOut columns\u000a        """\u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])    #will store data that has been analyzed\u000a        if type(dataOut)==str: dataOut=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list: dataOut = list(dataOut)\u000a\u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        #treat these separately later\u000a        allDataTypes.remove('ran')\u000a        #ready to go trhough standard data types\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut=='n':\u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if dataType=='all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew: dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew: dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew\u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a\u000a        #do the various analyses, keeping track of fails (e.g. mean of a string)\u000a        dataOutInvalid=[]\u000a        #add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        if 'order_raw' in dataOut:#move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. his should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal*=0 #prevent a divide-by-zero error\u000a                        else:\u000a                            thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError, 'You can only use analyses from numpy'\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:\u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a\u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid: dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a\u000a    def saveAsWideText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                  ):\u000a        """\u000a        Write a text file with the session, stimulus, and data values from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and various other analysis programs, means that some\u000a        information must be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each entry in there occurs in every row.\u000a        In builder, this will include any entries in the 'Experiment info' field of the 'Experiment settings' dialog.\u000a        In Coder, this information can be set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith', 'DOB':1970 Nov 16, 'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists.\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if appendFile:\u000a            writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.tsv', '.TSV', '.txt', '.TXT', '.csv', '.CSV']:\u000a            f = codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',': f = codecs.open(fileName+'.csv', writeFormat, encoding="utf-8")\u000a            else: f=codecs.open(fileName+'.txt',writeFormat, encoding = "utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of repetitions:\u000a\u000a        repsPerType={}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                #find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                #determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex]=0\u000a                else:\u000a                    repsPerType[trialTypeIndex]+=1\u000a                repThisType=repsPerType[trialTypeIndex]#what repeat are we on for this trial type?\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g. subject ID, date, etc) repeated every line if it exists:\u000a                if (self.extraInfo != None):\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # now collect the value from each trial of the variables named in the header:\u000a                for parameterName in header:\u000a                    # the header includes both trial and data variables, so need to check before accessing:\u000a                    if self.trialList[trialTypeIndex] and parameterName in self.trialList[trialTypeIndex]:\u000a                        nextEntry[parameterName] = self.trialList[trialTypeIndex][parameterName]\u000a                    elif parameterName in self.data:\u000a                        nextEntry[parameterName] = self.data[parameterName][trialTypeIndex][repThisType]\u000a                    else: # allow a null value if this parameter wasn't explicitly stored on this trial:\u000a                        nextEntry[parameterName] = ''\u000a\u000a                #store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0,"TrialNumber")\u000a        if (self.extraInfo != None):\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        if not matrixOnly:\u000a        # write the header row:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + parameterName + delim\u000a            f.write(nextLine[:-1] + '\u005cn') # remove the final orphaned tab character\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + unicode(trial[parameterName]) + delim\u000a            nextLine = nextLine[:-1] # remove the final orphaned tab character\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' %f.name)\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp()!=None:#update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). Please use `importConditions` for identical functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000adef importConditions(fileName, returnFieldNames=False):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler` `trialTypes` or to\u000a    :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a        - .csv:  import as a comma-separated-value file (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files. Sorry no support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all names are\u000a        OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            raise ImportError, 'Conditions file %s: Missing parameter name(s); empty cell(s) in the first row?' % fileName\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK: #tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError, 'Conditions file %s: %s%s"%s"' %(fileName, msg, os.linesep*2, name)\u000a\u000a    if fileName in ['None','none',None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        raise ImportError, 'Conditions file not found: %s' %os.path.abspath(fileName)\u000a\u000a    if fileName.endswith('.csv'):\u000a        #use csv import library to fetch the fieldNames\u000a        f = open(fileName, 'rU')#the U converts line endings to os.linesep (not unicode!)\u000a        trialsArr = numpy.recfromcsv(f)\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        f.close()\u000a        #convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial ={}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                if type(val)==numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    #if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        #exec('val=%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU') # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except:\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0] # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                thisTrial[fieldName] = row[fieldN] # type is correct, being .pkl\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for loading excel format files, but it was not found.'\u000a        try:\u000a            wb = load_workbook(filename = fileName)\u000a        except: # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        ws = wb.worksheets[0]\u000a        nCols = ws.get_highest_column()\u000a        nRows = ws.get_highest_row()\u000a\u000a        #get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        #loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):#skip header first row\u000a            thisTrial={}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                #if it looks like a list, convert it\u000a                if type(val) in [unicode, str] and (\u000a                        val.startswith('[') and val.endswith(']') or\u000a                        val.startswith('(') and val.endswith(')') ):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                 (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList,fieldNames)\u000a    else:\u000a        return trialList\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a\u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"],\u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``demo_trialHandler.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name=''):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in\u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a        """\u000a\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a\u000a            """\u000a        self.name=name\u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a\u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True\u000a\u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either\u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.otherData={} #a dict of lists where each should have the same length as the main data\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def __iter__(self):\u000a        return self\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity!=None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        #increment the counter of correct scores\u000a        if result==1:\u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additonal data to the handler, to be tracked alongside the result\u000a        data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData: #init the list\u000a            if self.thisTrialN>0:\u000a                self.otherData[dataName]=[None]*(self.thisTrialN-1) #might have run trals already\u000a            else:\u000a                self.otherData[dataName]=[]\u000a        #then add current value\u000a        self.otherData[dataName].append(value)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous. Please use one of\u000a        these instead:\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a\u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially\u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                self._intensityDec()\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                self._intensityInc()\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a\u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            #make it harder\u000a            self._intensityDec()\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a\u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!\u000a            #make it easier\u000a            self._intensityInc()\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a\u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a\u000a\u000a        #add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a        #test if we're done\u000a        if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a            len(self.intensities)>=self.nTrials:\u000a                self.finished=True\u000a        #new step size if necessary\u000a        if reversal and self._variableStep and self.finished==False:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                #we've gone beyond the list of step sizes so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        if self.finished==False:\u000a            #check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key])<self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv','.CSV']:\u000a            f= file(fileName,'w')\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a\u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', delim)\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', delim)\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', delim)\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', delim)\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved data to %s' %f.name)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a\u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a\u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        logging.info('saved data to %s' %fileName)\u000a\u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1:\u000a            logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' %f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addData(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name=''):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold..\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a\u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels\u000a                into decibels or log units and will move along the psychometric function with these values.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a\u000a        """\u000a\u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method,\u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal, name=name)\u000a\u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a\u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp=None\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  #remove the one that had been auto-generated\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError, "length of intensities and results input must be the same"\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addData(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a\u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        else:\u000a            scaled_intensity = intensity\u000a        return scaled_intensity\u000a\u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        else:\u000a            intensity = scaled_intensity\u000a        return intensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode()[0])\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest,\u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50, originPath=None, name=''):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or\u000a        QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above handlers)\u000a        a `label` to tag the staircase and a `startValSd` (only for QUEST\u000a        staircases). Any parameters not specified in the conditions file\u000a        will revert to the default for that individual handler.\u000a\u000a        If you need to custom the behaviour further you may want to look at the\u000a        recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than\u000a                that (so you can't have 3 repeats of the same staircase in a row\u000a                unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importTrialTypes`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't\u000a                also met its minimal reversals. See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                #do something with thisIntensity and thisOri\u000a\u000a                stairs.addData(correctIncorrect)#this is ESSENTIAL\u000a\u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a\u000a        """\u000a        self.name=name\u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a\u000a        #fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            logging.error('conditions parameter to MultiStairHandler should be a list, not a %s' %type(self.conditions))\u000a            return\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            logging.error('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest']:\u000a            if 'startVal' not in params:\u000a                logging.error('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params:\u000a                logging.error('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type=='quest':\u000a                logging.error("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            logging.error("MultiStairHandler `stairType` should be 'simple' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials,\u000a                'nUp':1, 'nDown':3, 'extraInfo':None,\u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type=='quest':\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None,\u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01,\u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None,\u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a\u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter\u000a                if paramName in condition.keys(): val=condition[paramName]\u000a                else: val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals,\u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown,\u000a                    extraInfo=extraInfo,\u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type=='quest':\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'],\u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval,\u000a                    method=method, stepType=stepType, beta=beta, delta=delta,\u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo,\u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        #if staircase.next() not called, staircaseHandler would not save the first intensity,\u000a        #Error: miss align intensities and responses\u000a        try:\u000a            self._nextIntensity =self.currentStaircase.next()#gets updated by self.addData()\u000a        except:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a            if len(self.runningStaircases)==0: #If finished,set finished flag \u000a                self.finished=True\u000a        #return value\u000a        if not self.finished:\u000a            #inform experiment of the condition (but not intensity, that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" %(self.name, key), value)\u000a                exp.addData(self.name+'.thisIndex', self.conditions.index(stair.condition))\u000a                exp.addData(self.name+'.thisRepN', stair.thisTrialN+1)\u000a                exp.addData(self.name+'.thisN', self.totalTrials)\u000a                exp.addData(self.name+'.direction', stair.currentDirection)\u000a                exp.addData(self.name+'.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name+'.stepType', stair.stepType)\u000a                exp.addData(self.name+'.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed byt he user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method=='random': numpy.random.shuffle(self.thisPassRemaining)\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.totalTrials+=1\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the curent trial that will not be used to control the\u000a        staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding the response\u000a        (0 or 1) or some other data concerning the trial so there is now a pair\u000a        of explicit methods:\u000a            addResponse(corr,intensity) #some data that alters the next trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't control staircase\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in [str, unicode]:\u000a            raise TypeError, "MultiStairHandler.addData should only receive corr/incorr. Use .addOtherData('datName',val)"\u000a    def saveAsPickle(self, fileName):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a        """\u000a        if self.totalTrials<1:\u000a            logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' %f.name)\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN==0: append=appendFile\u000a            else: append=True\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(fileName=fileName, sheetName=label,\u000a                matrixOnly=matrixOnly, appendFile=append)\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        if self.totalTrials<1:\u000a            logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(fileName=thisFileName, delim=delim,\u000a                matrixOnly=matrixOnly)\u000a    def printAsText(self,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs=len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN<(nStairs-1): thisMatrixOnly=True #never print info for first files\u000a            else: thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" %label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                matrixOnly=thisMatrixOnly)\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape: self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape: shape = self.dataShape\u000a        if not isinstance(names,basestring):\u000a            #recursively call this function until we have a string\u000a            for thisName in names: self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position==None:\u000a            #'ran' is always the first thing to update\u000a            if thisType=='ran':\u000a                repN = sum(self['ran'][self.trials.thisIndex])\u000a            else:\u000a                repN = sum(self['ran'][self.trials.thisIndex])-1#because it has already been updated\u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            logging.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    def __init__(self, fnName, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        raise "FitFunction is now fully DEPRECATED: use FitLogistic, FitWeibull etc instead"\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        #get some useful variables to help choose starting fit vals\u000a        #self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        #self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(self._eval, self.xx, self.yy)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params = self.params\u000a        global _chance\u000a        _chance=self.expectedMin\u000a        #_eval is a static method - must be done this way because the curve_fit\u000a        #function doesn't want to have any `self` object as first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params=self.params #so the user can set params for this particular inv\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)"""\u000a    #static mathods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy =  _chance + (1.0-_chance)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-_chance))) **(1.0/beta)\u000a        return xx\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    #static mathods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50<=0: c50=0.001\u000a        if n<=0: n=0.001\u000a        if rMax<=0: n=0.001\u000a        if rMin<=0: n=0.001\u000a        yy = rMin + (rMax-rMin)*(xx**n/(xx**n+c50**n))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy-rMin)/(rMax-rMin) #remove baseline and scale\u000a        #do we need to shift while fitting?\u000a        yScaled[yScaled<0]=0\u000a        xx = (yScaled*(c50)**n/(1-yScaled))**(1/n)\u000a        return xx\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    #static mathods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-_chance)/(yy-_chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*(special.erf(xx*xScale - xShift)/2.0+0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = (erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params\u000a    (a list with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is more in\u000a    with the parameters for the Weibull fit, for instance, it is less in keeping\u000a    with standard expectations of normal (Gaussian distributions) so in version\u000a    1.74.00 the parameters became the [centre,sd] of the normal distribution.\u000a\u000a    """\u000a    #static mathods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1-_chance)*(special.erf((xx-xShift)/sd)/2.0+0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        #xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erfinv() goes from -1:1\u000a        xx = xShift+sd*special.erfinv(( (yy-_chance)/(1-_chance) - 0.5 )*2)\u000a        return xx\u000a\u000a########################## End psychopy.data classes ##########################\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a\u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure\u000a\u000a    usage::\u000a\u000a        [intensity, meanCorrect, n] = functionFromStaircase(intensities, responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique' (where each bin is made from ALL data for exactly one intensity value)\u000a\u000a            intensity\u000a                is the center of an intensity bin\u000a\u000a            meanCorrect\u000a                is mean % correct in that bin\u000a\u000a            n\u000a                is number of responses contributing to that mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp=[]; binnedInten=[]; nPoints = []\u000a    if bins=='unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a\u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    depending on locale, can have unicode chars in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_dec = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        now_dec = time.strftime("%Y_%m_%d_%H%M", time.localtime())  # '2011_03_16_1307'\u000a\u000a    return now_dec\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in [str, unicode, numpy.string_, numpy.unicode_]:\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            raise AttributeError, "name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name))\u000a        else:\u000a            raise AttributeError, "name %s (type %s) could not be converted to a string" % (name, type(name))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a\u000a
p1538
sg1336
(lp1539
sg1338
I211564400
sg10
g1389
sg6
g1340
sg1341
I1
sg1342
I63
sg19
g20
sg1343
g1
(g1344
g1345
(dp1540
g17
g1367
(g1350
(I0
tS'b'
tRp1541
(I1
(I63
I1
tg1392
I00
(lp1542
S'p'
aS'q'
aS'q'
aS'p'
aS'q'
aS'p'
aS'q'
aS'p'
aS'q'
aS'p'
aS'p'
aS'q'
aS'p'
aS'q'
aS'p'
aS'p'
aS'p'
aS'p'
aS'p'
aS'p'
aS'q'
aS'q'
aS'p'
aS'p'
aS'q'
aS'p'
aS'q'
aS'p'
aS'q'
aS'p'
aS'q'
aS'q'
aS'p'
aS'p'
aS'q'
aS'p'
aS'p'
aS'p'
aS'p'
aS'p'
aS'p'
aS'p'
aS'q'
aS'p'
aS'q'
aS'p'
aS'q'
aS'p'
aS'q'
aS'p'
aS'q'
aS'q'
aS'q'
aS'p'
aS'p'
aS'q'
aS'q'
aS'q'
aS'q'
aS'p'
aS'p'
aS'p'
aS'q'
atbsg16
g1367
(g1350
(I0
tS'b'
tRp1543
(I1
(I63
I1
tg1392
I00
(lp1544
g76
ag50
ag76
ag50
ag50
ag50
ag76
ag50
ag76
ag76
ag50
ag50
ag76
ag50
ag50
ag76
ag50
ag76
ag50
ag50
ag76
ag76
ag76
ag76
ag76
ag76
ag50
ag76
ag50
ag50
ag50
ag50
ag50
ag50
ag50
ag76
ag50
ag50
ag76
ag50
ag76
ag50
ag50
ag50
ag76
ag50
ag50
ag76
ag50
ag50
ag50
ag76
ag50
ag50
ag50
ag50
ag50
ag76
ag50
ag50
ag50
ag76
ag76
atbsg15
g1367
(g1350
(I0
tS'b'
tRp1545
(I1
(I63
I1
tg1392
I00
(lp1546
g47
ag47
ag55
ag55
ag47
ag55
ag55
ag55
ag47
ag47
ag55
ag55
ag55
ag55
ag55
ag55
ag55
ag55
ag55
ag55
ag47
ag47
ag55
ag55
ag47
ag55
ag47
ag55
ag55
ag47
ag47
ag47
ag47
ag47
ag47
ag47
ag55
ag47
ag55
ag55
ag55
ag47
ag55
ag55
ag55
ag47
ag47
ag47
ag55
ag55
ag55
ag55
ag55
ag47
ag55
ag55
ag55
ag55
ag55
ag55
ag47
ag55
ag55
atbsg1347
g1348
(g1349
g1350
g1351
S'b'
tRp1547
(I1
(I63
I1
tg1353
I00
S'\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg18
g1348
(g1349
g1350
g1351
S'b'
tRp1548
(I1
(I63
I1
tg1353
I00
S"\xb89\xad?\xf0\xfa\x18?\xd4%\x1b?\xf0~\xe6>(\x98\x19?\x18'\xed>\x94\x87\x19?\xf8d\xe7>\x10\xcb\xe6>Xj\xe6>`\x96\xe6>0\x89\x17?\x04\x8e<?x9\xe6>x+\xe3>(\xc0\xe7>P\xe0\x19?\x98\x93\xe8>0<\xe7>\x80\xfa\x1b?\x80\x1a\xe7>\xec\xdc@?,\x94\x19?\x9cK\x19?\xa4\x13B?\xb8\xe4\x18?\xe0\xaa\xe9>(\xeb\xe8>\xf0:\xeb>x\xb5\xe5>\x88\x85\x9a>@\x0e\xeb>(\x95\xe9>\xe0\xbf\x1d?\x0c\xdeC?\xb0\xea\xeb>4g\x19?\xd4\x03k?\xb4\x83\x19?\x0c\xdaG?\xb0\xf4\x1d?\xd8\xa2\x1d?\x0c\x92n?<\x9b\x15?\x84\x85;?<\x84\x19?\xcc\xef<?Lf\x18?\xc8\xdd\x14?LY\x19?@\xae\xe6>4\xc4i?\xd8\xf3\x1d?DID?tz\x88?\xb0{\xeb>\xa0;\xe8>\xf04\xea>\xf0\xccl? *\xe6>\x90\xbc\xeb>\xf4\xbfD?\xa8\x81\xe6>"
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg14
g1367
(g1350
(I0
tS'b'
tRp1549
(I1
(I63
I1
tg1392
I00
(lp1550
g47
ag55
ag55
ag47
ag55
ag47
ag55
ag47
ag47
ag47
ag47
ag47
ag55
ag47
ag47
ag55
ag47
ag55
ag47
ag47
ag47
ag47
ag55
ag55
ag47
ag55
ag55
ag55
ag47
ag55
ag55
ag55
ag55
ag55
ag55
ag47
ag47
ag55
ag55
ag47
ag55
ag55
ag47
ag47
ag55
ag55
ag55
ag47
ag47
ag47
ag47
ag55
ag47
ag55
ag47
ag47
ag47
ag55
ag47
ag47
ag55
ag55
ag55
atbsg1354
g1348
(g1349
g1350
g1351
S'b'
tRp1551
(I1
(I63
I1
tg1353
I00
S'\x00\x00\x00\x00\x00\x00\x80?\x00\x00\x00@\x00\x00@@\x00\x00\x80@\x00\x00\xa0@\x00\x00\xc0@\x00\x00\xe0@\x00\x00\x00A\x00\x00\x10A\x00\x00 A\x00\x000A\x00\x00@A\x00\x00PA\x00\x00`A\x00\x00pA\x00\x00\x80A\x00\x00\x88A\x00\x00\x90A\x00\x00\x98A\x00\x00\xa0A\x00\x00\xa8A\x00\x00\xb0A\x00\x00\xb8A\x00\x00\xc0A\x00\x00\xc8A\x00\x00\xd0A\x00\x00\xd8A\x00\x00\xe0A\x00\x00\xe8A\x00\x00\xf0A\x00\x00\xf8A\x00\x00\x00B\x00\x00\x04B\x00\x00\x08B\x00\x00\x0cB\x00\x00\x10B\x00\x00\x14B\x00\x00\x18B\x00\x00\x1cB\x00\x00 B\x00\x00$B\x00\x00(B\x00\x00,B\x00\x000B\x00\x004B\x00\x008B\x00\x00<B\x00\x00@B\x00\x00DB\x00\x00HB\x00\x00LB\x00\x00PB\x00\x00TB\x00\x00XB\x00\x00\\B\x00\x00`B\x00\x00dB\x00\x00hB\x00\x00lB\x00\x00pB\x00\x00tB\x00\x00xB'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
NtbstRp1552
(dp1553
g1358
(dp1554
g16
I00
sg15
I00
sg1347
I01
sg14
I00
sg17
I00
sg18
I01
sg1354
I01
ssg1360
g1536
sg1361
(lp1555
g1347
ag1354
ag14
ag15
ag16
ag17
ag18
asg1363
(lp1556
I63
aI1
asbsg1365
I63
sg1366
g1367
(g1350
(I0
tS'b'
tRp1557
(I1
(I63
I1
tg52
I00
S'\x00\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\x03\x00\x00\x00\x04\x00\x00\x00\x05\x00\x00\x00\x06\x00\x00\x00\x07\x00\x00\x00\x08\x00\x00\x00\t\x00\x00\x00\n\x00\x00\x00\x0b\x00\x00\x00\x0c\x00\x00\x00\r\x00\x00\x00\x0e\x00\x00\x00\x0f\x00\x00\x00\x10\x00\x00\x00\x11\x00\x00\x00\x12\x00\x00\x00\x13\x00\x00\x00\x14\x00\x00\x00\x15\x00\x00\x00\x16\x00\x00\x00\x17\x00\x00\x00\x18\x00\x00\x00\x19\x00\x00\x00\x1a\x00\x00\x00\x1b\x00\x00\x00\x1c\x00\x00\x00\x1d\x00\x00\x00\x1e\x00\x00\x00\x1f\x00\x00\x00 \x00\x00\x00!\x00\x00\x00"\x00\x00\x00#\x00\x00\x00$\x00\x00\x00%\x00\x00\x00&\x00\x00\x00\'\x00\x00\x00(\x00\x00\x00)\x00\x00\x00*\x00\x00\x00+\x00\x00\x00,\x00\x00\x00-\x00\x00\x00.\x00\x00\x00/\x00\x00\x000\x00\x00\x001\x00\x00\x002\x00\x00\x003\x00\x00\x004\x00\x00\x005\x00\x00\x006\x00\x00\x007\x00\x00\x008\x00\x00\x009\x00\x00\x00:\x00\x00\x00;\x00\x00\x00<\x00\x00\x00=\x00\x00\x00>\x00\x00\x00'
tbsg1369
I01
sg1370
I1
sg1371
I-1
sg1372
(lp1558
g1
(g1374
g1345
(dp1559
g697
I1
sg691
I0
sg690
I2
stRp1560
ag1
(g1374
g1345
(dp1561
g697
I2
sg691
I1
sg690
I1
stRp1562
ag1
(g1374
g1345
(dp1563
g697
I2
sg691
I2
sg690
I1
stRp1564
ag1
(g1374
g1345
(dp1565
g697
I1
sg691
I3
sg690
I2
stRp1566
ag1
(g1374
g1345
(dp1567
g697
I2
sg691
I4
sg690
I1
stRp1568
ag1
(g1374
g1345
(dp1569
g697
I1
sg691
I5
sg690
I2
stRp1570
ag1
(g1374
g1345
(dp1571
g697
I2
sg691
I6
sg690
I1
stRp1572
ag1
(g1374
g1345
(dp1573
g697
I1
sg691
I7
sg690
I2
stRp1574
ag1
(g1374
g1345
(dp1575
g697
I1
sg691
I8
sg690
I2
stRp1576
ag1
(g1374
g1345
(dp1577
g697
I1
sg691
I9
sg690
I2
stRp1578
ag1
(g1374
g1345
(dp1579
g697
I1
sg691
I10
sg690
I2
stRp1580
ag1
(g1374
g1345
(dp1581
g697
I1
sg691
I11
sg690
I2
stRp1582
ag1
(g1374
g1345
(dp1583
g697
I2
sg691
I12
sg690
I1
stRp1584
ag1
(g1374
g1345
(dp1585
g697
I1
sg691
I13
sg690
I2
stRp1586
ag1
(g1374
g1345
(dp1587
g697
I1
sg691
I14
sg690
I2
stRp1588
ag1
(g1374
g1345
(dp1589
g697
I2
sg691
I15
sg690
I1
stRp1590
ag1
(g1374
g1345
(dp1591
g697
I1
sg691
I16
sg690
I2
stRp1592
ag1
(g1374
g1345
(dp1593
g697
I2
sg691
I17
sg690
I1
stRp1594
ag1
(g1374
g1345
(dp1595
g697
I1
sg691
I18
sg690
I2
stRp1596
ag1
(g1374
g1345
(dp1597
g697
I1
sg691
I19
sg690
I2
stRp1598
ag1
(g1374
g1345
(dp1599
g697
I1
sg691
I20
sg690
I2
stRp1600
ag1
(g1374
g1345
(dp1601
g697
I1
sg691
I21
sg690
I2
stRp1602
ag1
(g1374
g1345
(dp1603
g697
I2
sg691
I22
sg690
I1
stRp1604
ag1
(g1374
g1345
(dp1605
g697
I2
sg691
I23
sg690
I1
stRp1606
ag1
(g1374
g1345
(dp1607
g697
I1
sg691
I24
sg690
I2
stRp1608
ag1
(g1374
g1345
(dp1609
g697
I2
sg691
I25
sg690
I1
stRp1610
ag1
(g1374
g1345
(dp1611
g697
I2
sg691
I26
sg690
I1
stRp1612
ag1
(g1374
g1345
(dp1613
g697
I2
sg691
I27
sg690
I1
stRp1614
ag1
(g1374
g1345
(dp1615
g697
I1
sg691
I28
sg690
I2
stRp1616
ag1
(g1374
g1345
(dp1617
g697
I2
sg691
I29
sg690
I1
stRp1618
ag1
(g1374
g1345
(dp1619
g697
I2
sg691
I30
sg690
I1
stRp1620
ag1
(g1374
g1345
(dp1621
g697
I2
sg691
I31
sg690
I1
stRp1622
ag1
(g1374
g1345
(dp1623
g697
I2
sg691
I32
sg690
I1
stRp1624
ag1
(g1374
g1345
(dp1625
g697
I2
sg691
I33
sg690
I1
stRp1626
ag1
(g1374
g1345
(dp1627
g697
I2
sg691
I34
sg690
I1
stRp1628
ag1
(g1374
g1345
(dp1629
g697
I1
sg691
I35
sg690
I2
stRp1630
ag1
(g1374
g1345
(dp1631
g697
I1
sg691
I36
sg690
I2
stRp1632
ag1
(g1374
g1345
(dp1633
g697
I2
sg691
I37
sg690
I1
stRp1634
ag1
(g1374
g1345
(dp1635
g697
I2
sg691
I38
sg690
I1
stRp1636
ag1
(g1374
g1345
(dp1637
g697
I1
sg691
I39
sg690
I2
stRp1638
ag1
(g1374
g1345
(dp1639
g697
I2
sg691
I40
sg690
I1
stRp1640
ag1
(g1374
g1345
(dp1641
g697
I2
sg691
I41
sg690
I1
stRp1642
ag1
(g1374
g1345
(dp1643
g697
I1
sg691
I42
sg690
I2
stRp1644
ag1
(g1374
g1345
(dp1645
g697
I1
sg691
I43
sg690
I2
stRp1646
ag1
(g1374
g1345
(dp1647
g697
I2
sg691
I44
sg690
I1
stRp1648
ag1
(g1374
g1345
(dp1649
g697
I2
sg691
I45
sg690
I1
stRp1650
ag1
(g1374
g1345
(dp1651
g697
I2
sg691
I46
sg690
I1
stRp1652
ag1
(g1374
g1345
(dp1653
g697
I1
sg691
I47
sg690
I2
stRp1654
ag1
(g1374
g1345
(dp1655
g697
I1
sg691
I48
sg690
I2
stRp1656
ag1
(g1374
g1345
(dp1657
g697
I1
sg691
I49
sg690
I2
stRp1658
ag1
(g1374
g1345
(dp1659
g697
I1
sg691
I50
sg690
I2
stRp1660
ag1
(g1374
g1345
(dp1661
g697
I2
sg691
I51
sg690
I1
stRp1662
ag1
(g1374
g1345
(dp1663
g697
I1
sg691
I52
sg690
I2
stRp1664
ag1
(g1374
g1345
(dp1665
g697
I2
sg691
I53
sg690
I1
stRp1666
ag1
(g1374
g1345
(dp1667
g697
I1
sg691
I54
sg690
I2
stRp1668
ag1
(g1374
g1345
(dp1669
g697
I1
sg691
I55
sg690
I2
stRp1670
ag1
(g1374
g1345
(dp1671
g697
I1
sg691
I56
sg690
I2
stRp1672
ag1
(g1374
g1345
(dp1673
g697
I2
sg691
I57
sg690
I1
stRp1674
ag1
(g1374
g1345
(dp1675
g697
I1
sg691
I58
sg690
I2
stRp1676
ag1
(g1374
g1345
(dp1677
g697
I1
sg691
I59
sg690
I2
stRp1678
ag1
(g1374
g1345
(dp1679
g697
I2
sg691
I60
sg690
I1
stRp1680
ag1
(g1374
g1345
(dp1681
g697
I2
sg691
I61
sg690
I1
stRp1682
ag1
(g1374
g1345
(dp1683
g697
I2
sg691
I62
sg690
I1
stRp1684
asg1379
Nsg1380
g1318
sg1381
I0
sg1382
g1383
sg1384
I01
sbasS'savePickle'
p1685
I01
sb.